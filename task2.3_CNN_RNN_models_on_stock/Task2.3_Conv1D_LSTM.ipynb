{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "import classification_models\n",
    "from classification_models import GetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入train数据\n",
    "a=np.load(\"train_data.npy\")\n",
    "b=a.reshape([a.shape[0],a.shape[1]*a.shape[2]])\n",
    "c=b[~np.isnan(b).any(axis=1),:]\n",
    "train_data=c.reshape([c.shape[0], a.shape[1],a.shape[2]])\n",
    "d=np.load(\"train_label.npy\").reshape(-1,1)\n",
    "train_label=d[~np.isnan(b).any(axis=1),:].reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入valid数据\n",
    "a=np.load(\"valid_data.npy\")\n",
    "b=a.reshape([a.shape[0],a.shape[1]*a.shape[2]])\n",
    "c=b[~np.isnan(b).any(axis=1),:]\n",
    "valid_data=c.reshape([c.shape[0], a.shape[1],a.shape[2]])\n",
    "d=np.load(\"valid_label.npy\").reshape(-1,1)\n",
    "valid_label=d[~np.isnan(b).any(axis=1),:].reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=np.transpose(train_data,(0,2,1))\n",
    "valid_data=np.transpose(valid_data,(0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_precision(model,images,labels,device,predict_type):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct=0\n",
    "        total=0\n",
    "        images=images.type(torch.FloatTensor)\n",
    "        labels=labels.type(torch.FloatTensor)\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs=model(images)\n",
    "        _,predicted=torch.max(outputs.data,1)\n",
    "        total+=sum(predicted)\n",
    "        correct+=(sum(predicted*labels))\n",
    "        print('precision of the model on the'+predict_type+'data: {}%'.format(100*correct/total))\n",
    "    model.train()\n",
    "    return predicted, 100*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建CONV1D-LSTM Model (Many-to-One)\n",
    "class CONV1D_LSTM(nn.Module):\n",
    "    def __init__(self ,in_channel,out_channel, hidden_size, num_layers, num_classes,device=torch.device(\"cuda:1\")):\n",
    "        super(CONV1D_LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channel, out_channels=out_channel,kernel_size=1, stride=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channel)\n",
    "        self.conv2 = nn.Conv1d(in_channels=out_channel, out_channels=out_channel,kernel_size=1, stride=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channel)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.lstm = nn.LSTM(out_channel, hidden_size, num_layers, batch_first=True)  # batch_first=True仅仅针对输入而言\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight.to(device), mode='fan_out', nonlinearity='relu')\n",
    "                   \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #forward prop\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out=torch.transpose(out,2,1)\n",
    "        #因为pytorch里lstm和conv1d的input sequence位置不一样，需要调整。\n",
    "        \n",
    "        # 设置初始状态h_0与c_0的状态是初始的状态，一般设置为0，尺寸是,x.size(0)\n",
    "        h0 = Variable(torch.zeros(self.num_layers, out.size(0), self.hidden_size)).to(device)\n",
    "        c0 = Variable(torch.zeros(self.num_layers, out.size(0), self.hidden_size)).to(device)\n",
    "\n",
    "        # Forward propagate RNN\n",
    "        out, (h_n, c_n) = self.lstm(out, (h0, c0))  # 送入一个初始的x值，作为输入以及(h0, c0)\n",
    "\n",
    "        # Decode hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])  # output也是batch_first, 实际上h_n与c_n并不是batch_first\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv1DLSTM trial 1\n",
    "# Hyper Parameters\n",
    "sequence_length = 10  # 序列长度，将图像的每一列作为一个序列\n",
    "in_channel = 42\n",
    "out_channel=32\n",
    "hidden_size = 64  # 隐藏层的size\n",
    "num_layers =  3 # 有多少层\n",
    "\n",
    "num_classes = 2\n",
    "batch_size = 256\n",
    "num_epochs = 700\n",
    "learning_rate = 0.001\n",
    "\n",
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=GetLoader(train_data,train_label)\n",
    "valid=GetLoader(valid_data,valid_label)\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train,batch_size=batch_size,shuffle=True,num_workers=0)\n",
    "valid_loader=torch.utils.data.DataLoader(dataset=valid,batch_size=valid_data.shape[0],shuffle=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d_lstm = CONV1D_LSTM(in_channel=in_channel, out_channel=out_channel,\n",
    "                   hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes,device=device)\n",
    "conv1d_lstm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(conv1d_lstm.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step=0\n",
    "train_precision=[]\n",
    "valid_precision=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images=images.type(torch.FloatTensor)\n",
    "        labels=labels.type(torch.FloatTensor)\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        #forward pass\n",
    "        outputs=conv1d_lstm(images)\n",
    "        loss=loss_function(outputs,labels.long())\n",
    "        \n",
    "        #Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_step+=1\n",
    "        if (total_step)%1000==0:\n",
    "            print(\"Epoch [{}/{}],step[{}] Loss:{:.4f}\".format(epoch+1,num_epochs,total_step,loss.item()))\n",
    "            _,train_pre=predict_precision(conv1d_lstm,images,labels,device,predict_type='training')\n",
    "            train_precision.append(train_pre)\n",
    "            for images, labels in valid_loader:\n",
    "                _,valid_pre=predict_precision(conv1d_lstm,images,labels,device,predict_type='validation')\n",
    "            valid_precision.append(valid_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_precision,label=\"training precision\")\n",
    "plt.plot(valid_precision,label=\"validation precision\")\n",
    "plt.title(\"conv1d_lstm on stock\")\n",
    "plt.xlabel(\"1000*x training step\")\n",
    "plt.ylabel(\"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv1D_LSTM trial 1 总结:\n",
    "#batch_size，learning_rate等参数全部继承LSTM实验中筛选出的最优参数\n",
    "#整体效果并不好，在44000-55000step中可以稳定保证valid precision在0.53-0.54间，之后由于过拟合 valid precision整体下降\n",
    "#吸取LSTM实验中的教训，目前没有找到特别好的方法减小过拟合\n",
    "#故下一步试验改变网络结构，将LSTM的hidden_layer缩小到一层进一步尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv1DLSTM trial 2\n",
    "# Hyper Parameters\n",
    "sequence_length = 10  # 序列长度，将图像的每一列作为一个序列\n",
    "in_channel = 42\n",
    "out_channel=32\n",
    "hidden_size = 64  # 隐藏层的size\n",
    "num_layers =  1 # 有多少层\n",
    "\n",
    "num_classes = 2\n",
    "batch_size = 256\n",
    "num_epochs = 700\n",
    "learning_rate = 0.001\n",
    "\n",
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d_lstm = CONV1D_LSTM(in_channel=in_channel, out_channel=out_channel,\n",
    "                   hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes,device=device)\n",
    "conv1d_lstm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(conv1d_lstm.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step=0\n",
    "train_precision=[]\n",
    "valid_precision=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images=images.type(torch.FloatTensor)\n",
    "        labels=labels.type(torch.FloatTensor)\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        #forward pass\n",
    "        outputs=conv1d_lstm(images)\n",
    "        loss=loss_function(outputs,labels.long())\n",
    "        \n",
    "        #Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_step+=1\n",
    "        if (total_step)%1000==0:\n",
    "            print(\"Epoch [{}/{}],step[{}] Loss:{:.4f}\".format(epoch+1,num_epochs,total_step,loss.item()))\n",
    "            _,train_pre=predict_precision(conv1d_lstm,images,labels,device,predict_type='training')\n",
    "            train_precision.append(train_pre)\n",
    "            for images, labels in valid_loader:\n",
    "                _,valid_pre=predict_precision(conv1d_lstm,images,labels,device,predict_type='validation')\n",
    "            valid_precision.append(valid_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_precision,label=\"training precision\")\n",
    "plt.plot(valid_precision,label=\"validation precision\")\n",
    "plt.title(\"conv1d_lstm on stock\")\n",
    "plt.xlabel(\"1000*x training step\")\n",
    "plt.ylabel(\"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv1D_LSTM trial 2 总结:在将LSTM缩减为一层后模型在valid数据集的表现下降了一个档次，没有任何一段可以稳定超过0.53\n",
    "#由于LSTM hidden layer是唯一变量，而再将其减小后模型表现变差了，故怀疑是LSTM的比重减小是原因\n",
    "#下一步试验将LSTM hidden layer增加为2再尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv1DLSTM trial 3\n",
    "# Hyper Parameters\n",
    "sequence_length = 10  # 序列长度，将图像的每一列作为一个序列\n",
    "in_channel = 42\n",
    "out_channel=32\n",
    "hidden_size = 64  # 隐藏层的size\n",
    "num_layers =  2 # 有多少层\n",
    "\n",
    "num_classes = 2\n",
    "batch_size = 256\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.001\n",
    "\n",
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d_lstm = CONV1D_LSTM(in_channel=in_channel, out_channel=out_channel,\n",
    "                   hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes,device=device)\n",
    "conv1d_lstm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(conv1d_lstm.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step=0\n",
    "train_precision=[]\n",
    "valid_precision=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images=images.type(torch.FloatTensor)\n",
    "        labels=labels.type(torch.FloatTensor)\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        #forward pass\n",
    "        outputs=conv1d_lstm(images)\n",
    "        loss=loss_function(outputs,labels.long())\n",
    "        \n",
    "        #Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_step+=1\n",
    "        if (total_step)%1000==0:\n",
    "            print(\"Epoch [{}/{}],step[{}] Loss:{:.4f}\".format(epoch+1,num_epochs,total_step,loss.item()))\n",
    "            _,train_pre=predict_precision(conv1d_lstm,images,labels,device,predict_type='training')\n",
    "            train_precision.append(train_pre)\n",
    "            for images, labels in valid_loader:\n",
    "                _,valid_pre=predict_precision(conv1d_lstm,images,labels,device,predict_type='validation')\n",
    "            valid_precision.append(valid_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_precision,label=\"training precision\")\n",
    "plt.plot(valid_precision,label=\"validation precision\")\n",
    "plt.title(\"conv1d_lstm on stock\")\n",
    "plt.xlabel(\"1000*x training step\")\n",
    "plt.ylabel(\"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv1D_LSTM trial 3 总结：没有太大改观\n",
    "#经过思考，决定下一步尝试取消batch_norm进行尝试（normalization消除了conv产生的数据间距）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv1D_LSTM trial 4\n",
    "# 搭建CONV1D-LSTM Model (Many-to-One) without batch_norm\n",
    "class CONV1D_LSTM(nn.Module):\n",
    "    def __init__(self ,in_channel,out_channel, hidden_size, num_layers, num_classes,device=torch.device(\"cuda:1\")):\n",
    "        super(CONV1D_LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channel, out_channels=out_channel,kernel_size=1, stride=1, bias=False)\n",
    "        #self.bn1 = nn.BatchNorm1d(out_channel)\n",
    "        self.conv2 = nn.Conv1d(in_channels=out_channel, out_channels=out_channel,kernel_size=1, stride=1, bias=False)\n",
    "        #self.bn2 = nn.BatchNorm1d(out_channel)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.lstm = nn.LSTM(out_channel, hidden_size, num_layers, batch_first=True)  # batch_first=True仅仅针对输入而言\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight.to(device), mode='fan_out', nonlinearity='relu')\n",
    "                   \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #forward prop\n",
    "        out = self.conv1(x)\n",
    "        #out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        #out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out=torch.transpose(out,2,1)\n",
    "        #因为pytorch里lstm和conv1d的input sequence位置不一样，需要调整。\n",
    "        \n",
    "        # 设置初始状态h_0与c_0的状态是初始的状态，一般设置为0，尺寸是,x.size(0)\n",
    "        h0 = Variable(torch.zeros(self.num_layers, out.size(0), self.hidden_size)).to(device)\n",
    "        c0 = Variable(torch.zeros(self.num_layers, out.size(0), self.hidden_size)).to(device)\n",
    "\n",
    "        # Forward propagate RNN\n",
    "        out, (h_n, c_n) = self.lstm(out, (h0, c0))  # 送入一个初始的x值，作为输入以及(h0, c0)\n",
    "\n",
    "        # Decode hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])  # output也是batch_first, 实际上h_n与c_n并不是batch_first\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#LSTM non-BN trial\n",
    "for i in range(2,7):\n",
    "    # Hyper Parameters\n",
    "    sequence_length = 10  # 序列长度，将图像的每一列作为一个序列\n",
    "    in_channel = 42\n",
    "    out_channel=32\n",
    "    hidden_size = 64  # 隐藏层的size\n",
    "    num_layers =  2 # 有多少层\n",
    "\n",
    "    num_classes = 2\n",
    "    batch_size = 256\n",
    "    num_epochs = 800\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    device = torch.device(\"cuda:1\")\n",
    "    \n",
    "    conv1d_lstm = CONV1D_LSTM(in_channel=in_channel, out_channel=out_channel,\n",
    "                               hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes,device=device)\n",
    "    conv1d_lstm.to(device)\n",
    "    \n",
    "    # Loss and Optimizer\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(conv1d_lstm.parameters(), lr=learning_rate)\n",
    "    \n",
    "    total_step=0\n",
    "    train_precision=[]\n",
    "    valid_precision=[]\n",
    "    \n",
    "    #训练过程\n",
    "    for epoch in range(num_epochs):\n",
    "        for data in train_loader:\n",
    "            images, labels = data\n",
    "            images=images.type(torch.FloatTensor)\n",
    "            labels=labels.type(torch.FloatTensor)\n",
    "            images=images.to(device)\n",
    "            labels=labels.to(device)\n",
    "            #forward pass\n",
    "            outputs=conv1d_lstm(images)\n",
    "            loss=loss_function(outputs,labels.long())\n",
    "        \n",
    "            #Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_step+=1\n",
    "            if (total_step)%1000==0:#each 10 iterations is one epoch\n",
    "                print(\"Epoch [{}/{}],step[{}] Loss:{:.4f}\".format(epoch+1,num_epochs,total_step,loss.item()))\n",
    "                _,train_pre=predict_precision(conv1d_lstm,images,labels,device,predict_type='training')\n",
    "                train_precision.append(train_pre)\n",
    "                for images, labels in valid_loader:\n",
    "                    _,valid_pre=predict_precision(conv1d_lstm,images,labels,device,predict_type='validation')\n",
    "                valid_precision.append(valid_pre)\n",
    "            \n",
    "    #plot\n",
    "    plt.plot(train_precision,label=\"training precision\")\n",
    "    plt.plot(valid_precision,label=\"validation precision\")\n",
    "    plt.title(\"conv1d_lstm NonBN trial hidden layer::\"+str(i))\n",
    "    plt.xlabel(\"1000*x training step\")\n",
    "    plt.ylabel(\"precision\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv1D_LSTM trial 4 总结：最高的validation precision明显有所提高，但是往往都在训练epoch较小时，所以对模型的真实性有所怀疑\n",
    "#下一步试验，不训练模型直接测试和用极少epoch测试效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv1D_LSTM trial 5 不训练就测试\n",
    "#选择hidden layer为5的模型做测试\n",
    "    # Hyper Parameters\n",
    "    sequence_length = 10  # 序列长度，将图像的每一列作为一个序列\n",
    "    in_channel = 42\n",
    "    out_channel=32\n",
    "    hidden_size = 64  # 隐藏层的size\n",
    "    num_layers =  2 # 有多少层\n",
    "\n",
    "    num_classes = 2\n",
    "    batch_size = 256\n",
    "    num_epochs = 100\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    device = torch.device(\"cuda:1\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision of the model on thevalidationdata: 51.38856887817383%\n",
      "precision of the model on thevalidationdata: 51.06849670410156%\n",
      "precision of the model on thevalidationdata: 51.11299514770508%\n",
      "precision of the model on thevalidationdata: 51.98850631713867%\n",
      "precision of the model on thevalidationdata: 0.0%\n",
      "precision of the model on thevalidationdata: 51.09861755371094%\n",
      "precision of the model on thevalidationdata: 51.05290222167969%\n",
      "precision of the model on thevalidationdata: 51.1104850769043%\n",
      "precision of the model on thevalidationdata: nan%\n",
      "precision of the model on thevalidationdata: 51.1104850769043%\n",
      "precision of the model on thevalidationdata: 51.10703659057617%\n",
      "precision of the model on thevalidationdata: nan%\n",
      "precision of the model on thevalidationdata: 55.26315689086914%\n",
      "precision of the model on thevalidationdata: 64.60674285888672%\n",
      "precision of the model on thevalidationdata: nan%\n",
      "precision of the model on thevalidationdata: 51.1104850769043%\n",
      "precision of the model on thevalidationdata: 51.1104850769043%\n",
      "precision of the model on thevalidationdata: nan%\n",
      "precision of the model on thevalidationdata: 100.0%\n",
      "precision of the model on thevalidationdata: 51.07766342163086%\n",
      "precision of the model on thevalidationdata: 51.09355163574219%\n",
      "precision of the model on thevalidationdata: 51.1104850769043%\n",
      "precision of the model on thevalidationdata: 51.1104850769043%\n",
      "precision of the model on thevalidationdata: 51.1104850769043%\n",
      "precision of the model on thevalidationdata: 51.1104850769043%\n",
      "precision of the model on thevalidationdata: 55.04450988769531%\n",
      "precision of the model on thevalidationdata: 51.1104850769043%\n",
      "precision of the model on thevalidationdata: nan%\n",
      "precision of the model on thevalidationdata: 51.10405731201172%\n",
      "precision of the model on thevalidationdata: 51.40464782714844%\n",
      "precision of the model on thevalidationdata: nan%\n",
      "precision of the model on thevalidationdata: 51.1104850769043%\n",
      "precision of the model on thevalidationdata: 51.066383361816406%\n",
      "precision of the model on thevalidationdata: 33.33333206176758%\n",
      "precision of the model on thevalidationdata: 51.121456146240234%\n",
      "precision of the model on thevalidationdata: 48.73203659057617%\n",
      "precision of the model on thevalidationdata: nan%\n",
      "precision of the model on thevalidationdata: 48.671913146972656%\n",
      "precision of the model on thevalidationdata: 51.1104850769043%\n",
      "precision of the model on thevalidationdata: 51.070594787597656%\n",
      "precision of the model on thevalidationdata: nan%\n",
      "precision of the model on thevalidationdata: 51.1104850769043%\n",
      "precision of the model on thevalidationdata: 66.66666412353516%\n",
      "precision of the model on thevalidationdata: 51.0297966003418%\n",
      "precision of the model on thevalidationdata: nan%\n",
      "precision of the model on thevalidationdata: 51.083656311035156%\n",
      "precision of the model on thevalidationdata: nan%\n",
      "precision of the model on thevalidationdata: nan%\n",
      "precision of the model on thevalidationdata: nan%\n",
      "precision of the model on thevalidationdata: 52.515296936035156%\n"
     ]
    }
   ],
   "source": [
    "arb=[]\n",
    "for i in range(50):\n",
    "    conv1d_lstm = CONV1D_LSTM(in_channel=in_channel, out_channel=out_channel,\n",
    "                               hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes,device=device)\n",
    "    conv1d_lstm.to(device)\n",
    "    \n",
    "    # Loss and Optimizer\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(conv1d_lstm.parameters(), lr=learning_rate)\n",
    "    #不训练直接测试\n",
    "    for images, labels in valid_loader:\n",
    "        _,valid_pre=predict_precision(conv1d_lstm,images,labels,device,predict_type='validation')\n",
    "        arb.append(valid_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc94c4c0fd0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(arb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv1D_LSTM trial 5 总结: 不训练就测试效果十分随机。\n",
    "#接下来利用极少的训练次数进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_precision={}\n",
    "    valid_precision={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100],step[1000] Loss:0.6369\n",
      "precision of the model on thetrainingdata: 60.41666793823242%\n",
      "precision of the model on thevalidationdata: 58.93290328979492%\n",
      "Epoch [12/100],step[2000] Loss:0.6022\n",
      "precision of the model on thetrainingdata: 65.4676284790039%\n",
      "precision of the model on thevalidationdata: 56.1988525390625%\n",
      "Epoch [18/100],step[3000] Loss:0.6104\n",
      "precision of the model on thetrainingdata: 65.89147186279297%\n",
      "precision of the model on thevalidationdata: 55.532955169677734%\n",
      "Epoch [24/100],step[4000] Loss:0.5618\n",
      "precision of the model on thetrainingdata: 70.09346008300781%\n",
      "precision of the model on thevalidationdata: 57.13924026489258%\n",
      "Epoch [30/100],step[5000] Loss:0.5073\n",
      "precision of the model on thetrainingdata: 79.61164855957031%\n",
      "precision of the model on thevalidationdata: 54.10591125488281%\n",
      "Epoch [36/100],step[6000] Loss:0.4978\n",
      "precision of the model on thetrainingdata: 62.79069900512695%\n",
      "precision of the model on thevalidationdata: 53.91376495361328%\n",
      "Epoch [42/100],step[7000] Loss:0.4905\n",
      "precision of the model on thetrainingdata: 69.56521606445312%\n",
      "precision of the model on thevalidationdata: 52.650909423828125%\n",
      "Epoch [48/100],step[8000] Loss:0.3905\n",
      "precision of the model on thetrainingdata: 83.63636016845703%\n",
      "precision of the model on thevalidationdata: 52.32899856567383%\n",
      "Epoch [54/100],step[9000] Loss:0.3477\n",
      "precision of the model on thetrainingdata: 78.86178588867188%\n",
      "precision of the model on thevalidationdata: 51.59458923339844%\n",
      "Epoch [60/100],step[10000] Loss:0.3083\n",
      "precision of the model on thetrainingdata: 82.53968048095703%\n",
      "precision of the model on thevalidationdata: 52.62375259399414%\n",
      "Epoch [66/100],step[11000] Loss:0.3106\n",
      "precision of the model on thetrainingdata: 88.6956558227539%\n",
      "precision of the model on thevalidationdata: 50.16144943237305%\n",
      "Epoch [72/100],step[12000] Loss:0.2728\n",
      "precision of the model on thetrainingdata: 91.80327606201172%\n",
      "precision of the model on thevalidationdata: 51.895450592041016%\n",
      "Epoch [78/100],step[13000] Loss:0.2283\n",
      "precision of the model on thetrainingdata: 93.45794677734375%\n",
      "precision of the model on thevalidationdata: 50.799461364746094%\n",
      "Epoch [84/100],step[14000] Loss:0.2039\n",
      "precision of the model on thetrainingdata: 87.02290344238281%\n",
      "precision of the model on thevalidationdata: 52.54294204711914%\n",
      "Epoch [90/100],step[15000] Loss:0.2082\n",
      "precision of the model on thetrainingdata: 94.11764526367188%\n",
      "precision of the model on thevalidationdata: 52.787967681884766%\n",
      "Epoch [96/100],step[16000] Loss:0.1523\n",
      "precision of the model on thetrainingdata: 95.5752182006836%\n",
      "precision of the model on thevalidationdata: 50.21165466308594%\n",
      "Epoch [6/100],step[1000] Loss:0.6230\n",
      "precision of the model on thetrainingdata: 54.09836196899414%\n",
      "precision of the model on thevalidationdata: 54.878047943115234%\n",
      "Epoch [12/100],step[2000] Loss:0.6283\n",
      "precision of the model on thetrainingdata: 55.47945022583008%\n",
      "precision of the model on thevalidationdata: 53.349876403808594%\n",
      "Epoch [18/100],step[3000] Loss:0.5390\n",
      "precision of the model on thetrainingdata: 63.20000076293945%\n",
      "precision of the model on thevalidationdata: 53.84805679321289%\n",
      "Epoch [24/100],step[4000] Loss:0.5361\n",
      "precision of the model on thetrainingdata: 70.4000015258789%\n",
      "precision of the model on thevalidationdata: 55.365108489990234%\n",
      "Epoch [30/100],step[5000] Loss:0.5397\n",
      "precision of the model on thetrainingdata: 76.19047546386719%\n",
      "precision of the model on thevalidationdata: 54.73499298095703%\n",
      "Epoch [36/100],step[6000] Loss:0.5227\n",
      "precision of the model on thetrainingdata: 71.64179229736328%\n",
      "precision of the model on thevalidationdata: 54.97591018676758%\n",
      "Epoch [42/100],step[7000] Loss:0.5132\n",
      "precision of the model on thetrainingdata: 71.42857360839844%\n",
      "precision of the model on thevalidationdata: 50.9229736328125%\n",
      "Epoch [48/100],step[8000] Loss:0.4232\n",
      "precision of the model on thetrainingdata: 84.61538696289062%\n",
      "precision of the model on thevalidationdata: 54.195011138916016%\n",
      "Epoch [54/100],step[9000] Loss:0.4299\n",
      "precision of the model on thetrainingdata: 82.40740966796875%\n",
      "precision of the model on thevalidationdata: 54.347293853759766%\n",
      "Epoch [60/100],step[10000] Loss:0.3336\n",
      "precision of the model on thetrainingdata: 87.1212158203125%\n",
      "precision of the model on thevalidationdata: 52.445194244384766%\n",
      "Epoch [66/100],step[11000] Loss:0.3183\n",
      "precision of the model on thetrainingdata: 89.47368621826172%\n",
      "precision of the model on thevalidationdata: 52.965389251708984%\n",
      "Epoch [72/100],step[12000] Loss:0.2327\n",
      "precision of the model on thetrainingdata: 94.06779479980469%\n",
      "precision of the model on thevalidationdata: 52.304039001464844%\n",
      "Epoch [78/100],step[13000] Loss:0.2138\n",
      "precision of the model on thetrainingdata: 92.92035675048828%\n",
      "precision of the model on thevalidationdata: 53.44371032714844%\n",
      "Epoch [84/100],step[14000] Loss:0.2207\n",
      "precision of the model on thetrainingdata: 91.81818389892578%\n",
      "precision of the model on thevalidationdata: 52.524532318115234%\n",
      "Epoch [90/100],step[15000] Loss:0.2110\n",
      "precision of the model on thetrainingdata: 88.52458953857422%\n",
      "precision of the model on thevalidationdata: 50.92776107788086%\n",
      "Epoch [96/100],step[16000] Loss:0.2150\n",
      "precision of the model on thetrainingdata: 91.089111328125%\n",
      "precision of the model on thevalidationdata: 52.07112121582031%\n",
      "Epoch [6/100],step[1000] Loss:0.6181\n",
      "precision of the model on thetrainingdata: 61.98347091674805%\n",
      "precision of the model on thevalidationdata: 55.85611343383789%\n",
      "Epoch [12/100],step[2000] Loss:0.6448\n",
      "precision of the model on thetrainingdata: 57.264957427978516%\n",
      "precision of the model on thevalidationdata: 54.058780670166016%\n",
      "Epoch [18/100],step[3000] Loss:0.5854\n",
      "precision of the model on thetrainingdata: 68.6868667602539%\n",
      "precision of the model on thevalidationdata: 53.33253860473633%\n",
      "Epoch [24/100],step[4000] Loss:0.5358\n",
      "precision of the model on thetrainingdata: 72.58064270019531%\n",
      "precision of the model on thevalidationdata: 56.37620544433594%\n",
      "Epoch [30/100],step[5000] Loss:0.4991\n",
      "precision of the model on thetrainingdata: 86.91588592529297%\n",
      "precision of the model on thevalidationdata: 52.02982711791992%\n",
      "Epoch [36/100],step[6000] Loss:0.4738\n",
      "precision of the model on thetrainingdata: 70.86614227294922%\n",
      "precision of the model on thevalidationdata: 51.49941635131836%\n",
      "Epoch [42/100],step[7000] Loss:0.4668\n",
      "precision of the model on thetrainingdata: 74.59016418457031%\n",
      "precision of the model on thevalidationdata: 52.422325134277344%\n",
      "Epoch [48/100],step[8000] Loss:0.3714\n",
      "precision of the model on thetrainingdata: 80.83333587646484%\n",
      "precision of the model on thevalidationdata: 52.82306671142578%\n",
      "Epoch [54/100],step[9000] Loss:0.2673\n",
      "precision of the model on thetrainingdata: 87.06896209716797%\n",
      "precision of the model on thevalidationdata: 51.97187423706055%\n",
      "Epoch [60/100],step[10000] Loss:0.2962\n",
      "precision of the model on thetrainingdata: 87.09677124023438%\n",
      "precision of the model on thevalidationdata: 51.11298751831055%\n",
      "Epoch [66/100],step[11000] Loss:0.2155\n",
      "precision of the model on thetrainingdata: 90.82569122314453%\n",
      "precision of the model on thevalidationdata: 51.598880767822266%\n",
      "Epoch [72/100],step[12000] Loss:0.1972\n",
      "precision of the model on thetrainingdata: 92.30769348144531%\n",
      "precision of the model on thevalidationdata: 52.277503967285156%\n",
      "Epoch [78/100],step[13000] Loss:0.1471\n",
      "precision of the model on thetrainingdata: 94.06779479980469%\n",
      "precision of the model on thevalidationdata: 51.14607238769531%\n",
      "Epoch [84/100],step[14000] Loss:0.1642\n",
      "precision of the model on thetrainingdata: 95.90164184570312%\n",
      "precision of the model on thevalidationdata: 51.5935173034668%\n",
      "Epoch [90/100],step[15000] Loss:0.0738\n",
      "precision of the model on thetrainingdata: 97.5999984741211%\n",
      "precision of the model on thevalidationdata: 53.40083694458008%\n",
      "Epoch [96/100],step[16000] Loss:0.1597\n",
      "precision of the model on thetrainingdata: 95.04132080078125%\n",
      "precision of the model on thevalidationdata: 50.380428314208984%\n",
      "Epoch [6/100],step[1000] Loss:0.6206\n",
      "precision of the model on thetrainingdata: 57.54716873168945%\n",
      "precision of the model on thevalidationdata: 55.87018585205078%\n",
      "Epoch [12/100],step[2000] Loss:0.5713\n",
      "precision of the model on thetrainingdata: 68.33333587646484%\n",
      "precision of the model on thevalidationdata: 56.349056243896484%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100],step[3000] Loss:0.5963\n",
      "precision of the model on thetrainingdata: 61.11111068725586%\n",
      "precision of the model on thevalidationdata: 54.15559768676758%\n",
      "Epoch [24/100],step[4000] Loss:0.5646\n",
      "precision of the model on thetrainingdata: 65.0%\n",
      "precision of the model on thevalidationdata: 56.25129318237305%\n",
      "Epoch [30/100],step[5000] Loss:0.5584\n",
      "precision of the model on thetrainingdata: 70.87378692626953%\n",
      "precision of the model on thevalidationdata: 55.489418029785156%\n",
      "Epoch [36/100],step[6000] Loss:0.5580\n",
      "precision of the model on thetrainingdata: 68.54838562011719%\n",
      "precision of the model on thevalidationdata: 55.03641891479492%\n",
      "Epoch [42/100],step[7000] Loss:0.5447\n",
      "precision of the model on thetrainingdata: 73.78640747070312%\n",
      "precision of the model on thevalidationdata: 54.02802276611328%\n",
      "Epoch [48/100],step[8000] Loss:0.4370\n",
      "precision of the model on thetrainingdata: 85.07462310791016%\n",
      "precision of the model on thevalidationdata: 55.63887405395508%\n",
      "Epoch [54/100],step[9000] Loss:0.4172\n",
      "precision of the model on thetrainingdata: 80.70175170898438%\n",
      "precision of the model on thevalidationdata: 55.32059860229492%\n",
      "Epoch [60/100],step[10000] Loss:0.3459\n",
      "precision of the model on thetrainingdata: 88.42974853515625%\n",
      "precision of the model on thevalidationdata: 53.38345718383789%\n",
      "Epoch [66/100],step[11000] Loss:0.3392\n",
      "precision of the model on thetrainingdata: 88.28829193115234%\n",
      "precision of the model on thevalidationdata: 52.771385192871094%\n",
      "Epoch [72/100],step[12000] Loss:0.2489\n",
      "precision of the model on thetrainingdata: 90.5660400390625%\n",
      "precision of the model on thevalidationdata: 54.16129684448242%\n",
      "Epoch [78/100],step[13000] Loss:0.2497\n",
      "precision of the model on thetrainingdata: 93.96551513671875%\n",
      "precision of the model on thevalidationdata: 52.99652099609375%\n",
      "Epoch [84/100],step[14000] Loss:0.1918\n",
      "precision of the model on thetrainingdata: 91.86991882324219%\n",
      "precision of the model on thevalidationdata: 50.5008544921875%\n",
      "Epoch [90/100],step[15000] Loss:0.1701\n",
      "precision of the model on thetrainingdata: 91.15044403076172%\n",
      "precision of the model on thevalidationdata: 52.11435317993164%\n",
      "Epoch [96/100],step[16000] Loss:0.1556\n",
      "precision of the model on thetrainingdata: 89.43089294433594%\n",
      "precision of the model on thevalidationdata: 49.99448776245117%\n",
      "Epoch [6/100],step[1000] Loss:0.6325\n",
      "precision of the model on thetrainingdata: 56.9892463684082%\n",
      "precision of the model on thevalidationdata: 53.96039581298828%\n",
      "Epoch [12/100],step[2000] Loss:0.6160\n",
      "precision of the model on thetrainingdata: 55.844154357910156%\n",
      "precision of the model on thevalidationdata: 58.19423294067383%\n",
      "Epoch [18/100],step[3000] Loss:0.5734\n",
      "precision of the model on thetrainingdata: 71.55963134765625%\n",
      "precision of the model on thevalidationdata: 57.06698226928711%\n",
      "Epoch [24/100],step[4000] Loss:0.5303\n",
      "precision of the model on thetrainingdata: 76.47058868408203%\n",
      "precision of the model on thevalidationdata: 55.630184173583984%\n",
      "Epoch [30/100],step[5000] Loss:0.5361\n",
      "precision of the model on thetrainingdata: 74.5762710571289%\n",
      "precision of the model on thevalidationdata: 55.660179138183594%\n",
      "Epoch [36/100],step[6000] Loss:0.5331\n",
      "precision of the model on thetrainingdata: 67.11409759521484%\n",
      "precision of the model on thevalidationdata: 54.27077102661133%\n",
      "Epoch [42/100],step[7000] Loss:0.4178\n",
      "precision of the model on thetrainingdata: 85.71428680419922%\n",
      "precision of the model on thevalidationdata: 52.906455993652344%\n",
      "Epoch [48/100],step[8000] Loss:0.3809\n",
      "precision of the model on thetrainingdata: 84.61538696289062%\n",
      "precision of the model on thevalidationdata: 50.79719161987305%\n",
      "Epoch [54/100],step[9000] Loss:0.3403\n",
      "precision of the model on thetrainingdata: 85.71428680419922%\n",
      "precision of the model on thevalidationdata: 52.76840591430664%\n",
      "Epoch [60/100],step[10000] Loss:0.2917\n",
      "precision of the model on thetrainingdata: 91.86991882324219%\n",
      "precision of the model on thevalidationdata: 51.990203857421875%\n",
      "Epoch [66/100],step[11000] Loss:0.2258\n",
      "precision of the model on thetrainingdata: 94.54545593261719%\n",
      "precision of the model on thevalidationdata: 54.323036193847656%\n",
      "Epoch [72/100],step[12000] Loss:0.2353\n",
      "precision of the model on thetrainingdata: 89.76377868652344%\n",
      "precision of the model on thevalidationdata: 51.09233474731445%\n",
      "Epoch [78/100],step[13000] Loss:0.1873\n",
      "precision of the model on thetrainingdata: 88.80596923828125%\n",
      "precision of the model on thevalidationdata: 49.85945129394531%\n",
      "Epoch [84/100],step[14000] Loss:0.2331\n",
      "precision of the model on thetrainingdata: 91.48936462402344%\n",
      "precision of the model on thevalidationdata: 51.21022033691406%\n",
      "Epoch [90/100],step[15000] Loss:0.1019\n",
      "precision of the model on thetrainingdata: 98.38710021972656%\n",
      "precision of the model on thevalidationdata: 52.37931442260742%\n",
      "Epoch [96/100],step[16000] Loss:0.1152\n",
      "precision of the model on thetrainingdata: 98.18181610107422%\n",
      "precision of the model on thevalidationdata: 52.293914794921875%\n",
      "Epoch [6/100],step[1000] Loss:0.6213\n",
      "precision of the model on thetrainingdata: 63.6363639831543%\n",
      "precision of the model on thevalidationdata: 54.91120147705078%\n",
      "Epoch [12/100],step[2000] Loss:0.5860\n",
      "precision of the model on thetrainingdata: 69.52381134033203%\n",
      "precision of the model on thevalidationdata: 56.269981384277344%\n",
      "Epoch [18/100],step[3000] Loss:0.5699\n",
      "precision of the model on thetrainingdata: 63.35877990722656%\n",
      "precision of the model on thevalidationdata: 55.544639587402344%\n",
      "Epoch [24/100],step[4000] Loss:0.5457\n",
      "precision of the model on thetrainingdata: 76.92308044433594%\n",
      "precision of the model on thevalidationdata: 57.60443878173828%\n",
      "Epoch [30/100],step[5000] Loss:0.5240\n",
      "precision of the model on thetrainingdata: 71.18643951416016%\n",
      "precision of the model on thevalidationdata: 55.38680648803711%\n",
      "Epoch [36/100],step[6000] Loss:0.5178\n",
      "precision of the model on thetrainingdata: 74.38016510009766%\n",
      "precision of the model on thevalidationdata: 53.128936767578125%\n",
      "Epoch [42/100],step[7000] Loss:0.4608\n",
      "precision of the model on thetrainingdata: 74.52830505371094%\n",
      "precision of the model on thevalidationdata: 53.25978088378906%\n",
      "Epoch [48/100],step[8000] Loss:0.4203\n",
      "precision of the model on thetrainingdata: 80.86956787109375%\n",
      "precision of the model on thevalidationdata: 53.31866455078125%\n",
      "Epoch [54/100],step[9000] Loss:0.3712\n",
      "precision of the model on thetrainingdata: 82.25806427001953%\n",
      "precision of the model on thevalidationdata: 52.16377639770508%\n",
      "Epoch [60/100],step[10000] Loss:0.2964\n",
      "precision of the model on thetrainingdata: 83.47107696533203%\n",
      "precision of the model on thevalidationdata: 51.56231689453125%\n",
      "Epoch [66/100],step[11000] Loss:0.2698\n",
      "precision of the model on thetrainingdata: 89.74359130859375%\n",
      "precision of the model on thevalidationdata: 51.9002571105957%\n",
      "Epoch [72/100],step[12000] Loss:0.1821\n",
      "precision of the model on thetrainingdata: 88.59648895263672%\n",
      "precision of the model on thevalidationdata: 51.793052673339844%\n",
      "Epoch [78/100],step[13000] Loss:0.1663\n",
      "precision of the model on thetrainingdata: 92.7272720336914%\n",
      "precision of the model on thevalidationdata: 51.01984405517578%\n",
      "Epoch [84/100],step[14000] Loss:0.1502\n",
      "precision of the model on thetrainingdata: 96.03174591064453%\n",
      "precision of the model on thevalidationdata: 52.96458435058594%\n",
      "Epoch [90/100],step[15000] Loss:0.1149\n",
      "precision of the model on thetrainingdata: 94.87179565429688%\n",
      "precision of the model on thevalidationdata: 51.157752990722656%\n",
      "Epoch [96/100],step[16000] Loss:0.1445\n",
      "precision of the model on thetrainingdata: 95.53571319580078%\n",
      "precision of the model on thevalidationdata: 51.57342529296875%\n",
      "Epoch [6/100],step[1000] Loss:0.6472\n",
      "precision of the model on thetrainingdata: 61.739131927490234%\n",
      "precision of the model on thevalidationdata: 52.63518142700195%\n",
      "Epoch [12/100],step[2000] Loss:0.6057\n",
      "precision of the model on thetrainingdata: 56.140350341796875%\n",
      "precision of the model on thevalidationdata: 55.981441497802734%\n",
      "Epoch [18/100],step[3000] Loss:0.5760\n",
      "precision of the model on thetrainingdata: 66.93548583984375%\n",
      "precision of the model on thevalidationdata: 56.36316680908203%\n",
      "Epoch [24/100],step[4000] Loss:0.5688\n",
      "precision of the model on thetrainingdata: 65.94203186035156%\n",
      "precision of the model on thevalidationdata: 50.34660720825195%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100],step[5000] Loss:0.5800\n",
      "precision of the model on thetrainingdata: 72.04301452636719%\n",
      "precision of the model on thevalidationdata: 53.51411056518555%\n",
      "Epoch [36/100],step[6000] Loss:0.5239\n",
      "precision of the model on thetrainingdata: 68.99224853515625%\n",
      "precision of the model on thevalidationdata: 50.55940246582031%\n",
      "Epoch [42/100],step[7000] Loss:0.4208\n",
      "precision of the model on thetrainingdata: 85.96491241455078%\n",
      "precision of the model on thevalidationdata: 53.188899993896484%\n",
      "Epoch [48/100],step[8000] Loss:0.3899\n",
      "precision of the model on thetrainingdata: 83.03571319580078%\n",
      "precision of the model on thevalidationdata: 52.115264892578125%\n",
      "Epoch [54/100],step[9000] Loss:0.2803\n",
      "precision of the model on thetrainingdata: 87.1212158203125%\n",
      "precision of the model on thevalidationdata: 51.89495086669922%\n",
      "Epoch [60/100],step[10000] Loss:0.3209\n",
      "precision of the model on thetrainingdata: 84.21052551269531%\n",
      "precision of the model on thevalidationdata: 50.7833366394043%\n",
      "Epoch [66/100],step[11000] Loss:0.1608\n",
      "precision of the model on thetrainingdata: 95.6140365600586%\n",
      "precision of the model on thevalidationdata: 49.469058990478516%\n",
      "Epoch [72/100],step[12000] Loss:0.2182\n",
      "precision of the model on thetrainingdata: 88.0434799194336%\n",
      "precision of the model on thevalidationdata: 51.05925369262695%\n",
      "Epoch [78/100],step[13000] Loss:0.1924\n",
      "precision of the model on thetrainingdata: 92.43697357177734%\n",
      "precision of the model on thevalidationdata: 50.91278076171875%\n",
      "Epoch [84/100],step[14000] Loss:0.1514\n",
      "precision of the model on thetrainingdata: 92.30769348144531%\n",
      "precision of the model on thevalidationdata: 52.112674713134766%\n",
      "Epoch [90/100],step[15000] Loss:0.1933\n",
      "precision of the model on thetrainingdata: 94.44444274902344%\n",
      "precision of the model on thevalidationdata: 50.70125198364258%\n",
      "Epoch [96/100],step[16000] Loss:0.1203\n",
      "precision of the model on thetrainingdata: 96.03174591064453%\n",
      "precision of the model on thevalidationdata: 50.80107498168945%\n",
      "Epoch [6/100],step[1000] Loss:0.6175\n",
      "precision of the model on thetrainingdata: 57.5%\n",
      "precision of the model on thevalidationdata: 54.419654846191406%\n",
      "Epoch [12/100],step[2000] Loss:0.5953\n",
      "precision of the model on thetrainingdata: 62.77372360229492%\n",
      "precision of the model on thevalidationdata: 54.30866241455078%\n",
      "Epoch [18/100],step[3000] Loss:0.6050\n",
      "precision of the model on thetrainingdata: 64.46280670166016%\n",
      "precision of the model on thevalidationdata: 54.69343566894531%\n",
      "Epoch [24/100],step[4000] Loss:0.5528\n",
      "precision of the model on thetrainingdata: 73.72881317138672%\n",
      "precision of the model on thevalidationdata: 53.91183853149414%\n",
      "Epoch [30/100],step[5000] Loss:0.4903\n",
      "precision of the model on thetrainingdata: 78.81356048583984%\n",
      "precision of the model on thevalidationdata: 54.398216247558594%\n",
      "Epoch [36/100],step[6000] Loss:0.5034\n",
      "precision of the model on thetrainingdata: 78.07017517089844%\n",
      "precision of the model on thevalidationdata: 52.06032180786133%\n",
      "Epoch [42/100],step[7000] Loss:0.4396\n",
      "precision of the model on thetrainingdata: 84.16666412353516%\n",
      "precision of the model on thevalidationdata: 52.00067138671875%\n",
      "Epoch [48/100],step[8000] Loss:0.3539\n",
      "precision of the model on thetrainingdata: 81.30081176757812%\n",
      "precision of the model on thevalidationdata: 50.54313278198242%\n",
      "Epoch [54/100],step[9000] Loss:0.2714\n",
      "precision of the model on thetrainingdata: 91.52542114257812%\n",
      "precision of the model on thevalidationdata: 54.468231201171875%\n",
      "Epoch [60/100],step[10000] Loss:0.2777\n",
      "precision of the model on thetrainingdata: 85.45454406738281%\n",
      "precision of the model on thevalidationdata: 49.619075775146484%\n",
      "Epoch [66/100],step[11000] Loss:0.2286\n",
      "precision of the model on thetrainingdata: 88.42974853515625%\n",
      "precision of the model on thevalidationdata: 49.780086517333984%\n",
      "Epoch [72/100],step[12000] Loss:0.1811\n",
      "precision of the model on thetrainingdata: 92.64705657958984%\n",
      "precision of the model on thevalidationdata: 50.42496109008789%\n",
      "Epoch [78/100],step[13000] Loss:0.2291\n",
      "precision of the model on thetrainingdata: 91.19999694824219%\n",
      "precision of the model on thevalidationdata: 49.2963752746582%\n",
      "Epoch [84/100],step[14000] Loss:0.1528\n",
      "precision of the model on thetrainingdata: 90.44117736816406%\n",
      "precision of the model on thevalidationdata: 49.282588958740234%\n",
      "Epoch [90/100],step[15000] Loss:0.1110\n",
      "precision of the model on thetrainingdata: 97.5999984741211%\n",
      "precision of the model on thevalidationdata: 51.918861389160156%\n",
      "Epoch [96/100],step[16000] Loss:0.1423\n",
      "precision of the model on thetrainingdata: 96.03960418701172%\n",
      "precision of the model on thevalidationdata: 52.83662414550781%\n",
      "Epoch [6/100],step[1000] Loss:0.6463\n",
      "precision of the model on thetrainingdata: 59.20000076293945%\n",
      "precision of the model on thevalidationdata: 49.75657272338867%\n",
      "Epoch [12/100],step[2000] Loss:0.6085\n",
      "precision of the model on thetrainingdata: 68.0%\n",
      "precision of the model on thevalidationdata: 55.79981231689453%\n",
      "Epoch [18/100],step[3000] Loss:0.6435\n",
      "precision of the model on thetrainingdata: 57.723575592041016%\n",
      "precision of the model on thevalidationdata: 55.4388427734375%\n",
      "Epoch [24/100],step[4000] Loss:0.5527\n",
      "precision of the model on thetrainingdata: 71.6814193725586%\n",
      "precision of the model on thevalidationdata: 54.468170166015625%\n",
      "Epoch [30/100],step[5000] Loss:0.4806\n",
      "precision of the model on thetrainingdata: 80.0%\n",
      "precision of the model on thevalidationdata: 53.77656173706055%\n",
      "Epoch [36/100],step[6000] Loss:0.5447\n",
      "precision of the model on thetrainingdata: 74.7899169921875%\n",
      "precision of the model on thevalidationdata: 51.31477355957031%\n",
      "Epoch [42/100],step[7000] Loss:0.4978\n",
      "precision of the model on thetrainingdata: 71.42857360839844%\n",
      "precision of the model on thevalidationdata: 52.145782470703125%\n",
      "Epoch [48/100],step[8000] Loss:0.3969\n",
      "precision of the model on thetrainingdata: 79.13043212890625%\n",
      "precision of the model on thevalidationdata: 51.02660369873047%\n",
      "Epoch [54/100],step[9000] Loss:0.3609\n",
      "precision of the model on thetrainingdata: 82.4427490234375%\n",
      "precision of the model on thevalidationdata: 52.12869644165039%\n",
      "Epoch [60/100],step[10000] Loss:0.3231\n",
      "precision of the model on thetrainingdata: 80.95237731933594%\n",
      "precision of the model on thevalidationdata: 50.62461853027344%\n",
      "Epoch [66/100],step[11000] Loss:0.2664\n",
      "precision of the model on thetrainingdata: 86.02941131591797%\n",
      "precision of the model on thevalidationdata: 49.93241882324219%\n",
      "Epoch [72/100],step[12000] Loss:0.2290\n",
      "precision of the model on thetrainingdata: 90.74073791503906%\n",
      "precision of the model on thevalidationdata: 51.93955612182617%\n",
      "Epoch [78/100],step[13000] Loss:0.1750\n",
      "precision of the model on thetrainingdata: 93.2203369140625%\n",
      "precision of the model on thevalidationdata: 49.7698974609375%\n",
      "Epoch [84/100],step[14000] Loss:0.1760\n",
      "precision of the model on thetrainingdata: 91.79104614257812%\n",
      "precision of the model on thevalidationdata: 51.99293899536133%\n",
      "Epoch [90/100],step[15000] Loss:0.1744\n",
      "precision of the model on thetrainingdata: 94.54545593261719%\n",
      "precision of the model on thevalidationdata: 52.983341217041016%\n",
      "Epoch [96/100],step[16000] Loss:0.1610\n",
      "precision of the model on thetrainingdata: 96.06299591064453%\n",
      "precision of the model on thevalidationdata: 51.1058349609375%\n",
      "Epoch [6/100],step[1000] Loss:0.6035\n",
      "precision of the model on thetrainingdata: 68.10344696044922%\n",
      "precision of the model on thevalidationdata: 57.83216857910156%\n",
      "Epoch [12/100],step[2000] Loss:0.5786\n",
      "precision of the model on thetrainingdata: 68.6868667602539%\n",
      "precision of the model on thevalidationdata: 57.86997604370117%\n",
      "Epoch [18/100],step[3000] Loss:0.5810\n",
      "precision of the model on thetrainingdata: 69.49152374267578%\n",
      "precision of the model on thevalidationdata: 56.50255584716797%\n",
      "Epoch [24/100],step[4000] Loss:0.6331\n",
      "precision of the model on thetrainingdata: 67.2727279663086%\n",
      "precision of the model on thevalidationdata: 52.7162971496582%\n",
      "Epoch [30/100],step[5000] Loss:0.5251\n",
      "precision of the model on thetrainingdata: 73.33333587646484%\n",
      "precision of the model on thevalidationdata: 55.49767303466797%\n",
      "Epoch [36/100],step[6000] Loss:0.5116\n",
      "precision of the model on thetrainingdata: 71.55172729492188%\n",
      "precision of the model on thevalidationdata: 55.03173065185547%\n",
      "Epoch [42/100],step[7000] Loss:0.4908\n",
      "precision of the model on thetrainingdata: 73.6434097290039%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision of the model on thevalidationdata: 50.8890266418457%\n",
      "Epoch [48/100],step[8000] Loss:0.4672\n",
      "precision of the model on thetrainingdata: 82.60869598388672%\n",
      "precision of the model on thevalidationdata: 53.31406784057617%\n",
      "Epoch [54/100],step[9000] Loss:0.3516\n",
      "precision of the model on thetrainingdata: 82.35294342041016%\n",
      "precision of the model on thevalidationdata: 52.27535629272461%\n",
      "Epoch [60/100],step[10000] Loss:0.2918\n",
      "precision of the model on thetrainingdata: 87.82608795166016%\n",
      "precision of the model on thevalidationdata: 52.12642288208008%\n",
      "Epoch [66/100],step[11000] Loss:0.2720\n",
      "precision of the model on thetrainingdata: 86.5079345703125%\n",
      "precision of the model on thevalidationdata: 53.458457946777344%\n",
      "Epoch [72/100],step[12000] Loss:0.2449\n",
      "precision of the model on thetrainingdata: 87.82608795166016%\n",
      "precision of the model on thevalidationdata: 54.05854415893555%\n",
      "Epoch [78/100],step[13000] Loss:0.2200\n",
      "precision of the model on thetrainingdata: 89.43089294433594%\n",
      "precision of the model on thevalidationdata: 51.87690353393555%\n",
      "Epoch [84/100],step[14000] Loss:0.1806\n",
      "precision of the model on thetrainingdata: 90.76923370361328%\n",
      "precision of the model on thevalidationdata: 51.25063705444336%\n",
      "Epoch [90/100],step[15000] Loss:0.1836\n",
      "precision of the model on thetrainingdata: 91.0569076538086%\n",
      "precision of the model on thevalidationdata: 49.97611999511719%\n",
      "Epoch [96/100],step[16000] Loss:0.1671\n",
      "precision of the model on thetrainingdata: 95.6140365600586%\n",
      "precision of the model on thevalidationdata: 52.754478454589844%\n"
     ]
    }
   ],
   "source": [
    "#Conv1D_LSTM trial 6 \n",
    "for i in range(10):    \n",
    "    #num_epoch调小为50进行测试\n",
    "    total_step=0\n",
    "    train_precision[str(i)]=[]\n",
    "    valid_precision[str(i)]=[]\n",
    "    conv1d_lstm = CONV1D_LSTM(in_channel=in_channel, out_channel=out_channel,\n",
    "                               hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes,device=device)\n",
    "    conv1d_lstm.to(device)\n",
    "    \n",
    "    # Loss and Optimizer\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(conv1d_lstm.parameters(), lr=learning_rate)\n",
    "    #训练过程\n",
    "    for epoch in range(num_epochs):\n",
    "        for data in train_loader:\n",
    "            images, labels = data\n",
    "            images=images.type(torch.FloatTensor)\n",
    "            labels=labels.type(torch.FloatTensor)\n",
    "            images=images.to(device)\n",
    "            labels=labels.to(device)\n",
    "            #forward pass\n",
    "            outputs=conv1d_lstm(images)\n",
    "            loss=loss_function(outputs,labels.long())\n",
    "        \n",
    "            #Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_step+=1\n",
    "            if (total_step)%1000==0:#each 10 iterations is one epoch\n",
    "                print(\"Epoch [{}/{}],step[{}] Loss:{:.4f}\".format(epoch+1,num_epochs,total_step,loss.item()))\n",
    "                _,train_pre=predict_precision(conv1d_lstm,images,labels,device,predict_type='training')\n",
    "                train_precision[str(i)].append(train_pre)\n",
    "                for images, labels in valid_loader:\n",
    "                    _,valid_pre=predict_precision(conv1d_lstm,images,labels,device,predict_type='validation')\n",
    "                valid_precision[str(i)].append(valid_pre)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'precision')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):    \n",
    "    plt.plot(train_precision[str(i)],c='blue')\n",
    "    plt.plot(valid_precision[str(i)],c='green')\n",
    "\n",
    "plt.legend([\"training\",\"validation\"])\n",
    "plt.title(\"conv1d_lstm trial 6\")\n",
    "plt.xlabel(\"1000*x training step\")\n",
    "plt.ylabel(\"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv1D_LSTM trial 5 总结: 在使用Conv1D_LSTM时用较小的epoch可以达到比较好的效果，并且的确是由训练得出的\n",
    "#下一步试验：验证LSTM和Conv1D_LSTM之间的模型的信号相关性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(42, 64, num_layers=4, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conv1D_LSTM trial 6：测试和LSTM模型之间的信号相关性，进一步验证conv1d的意义\n",
    "from classification_models import LSTM\n",
    "#LSTM trial 1\n",
    "#Hyper Parameters\n",
    "sequence_length = 10  # 序列长度，将图像的每一列作为一个序列\n",
    "input_size = 42  # 输入数据的维度\n",
    "hidden_size = 64  # 隐藏层的size\n",
    "num_layers =  4 # 有多少层\n",
    "\n",
    "num_classes = 2\n",
    "batch_size = 256\n",
    "num_epochs = 500\n",
    "learning_rate = 0.001\n",
    "\n",
    "device = torch.device(\"cuda:1\")\n",
    "\n",
    "lstm = LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes,device=device)\n",
    "lstm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=np.transpose(train_data,(0,2,1))\n",
    "valid_data=np.transpose(valid_data,(0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=GetLoader(train_data,train_label)\n",
    "valid=GetLoader(valid_data,valid_label)\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train,batch_size=batch_size,shuffle=True,num_workers=0)\n",
    "valid_loader=torch.utils.data.DataLoader(dataset=valid,batch_size=valid_data.shape[0],shuffle=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step=0\n",
    "lstm_train_precision=[]\n",
    "lstm_valid_precision=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/500],step[1000] Loss:0.5960\n",
      "precision of the model on thetrainingdata: 62.931034088134766%\n",
      "precision of the model on thevalidationdata: 53.86490249633789%\n",
      "Epoch [12/500],step[2000] Loss:0.5721\n",
      "precision of the model on thetrainingdata: 65.27777862548828%\n",
      "precision of the model on thevalidationdata: 52.987422943115234%\n",
      "Epoch [18/500],step[3000] Loss:0.5352\n",
      "precision of the model on thetrainingdata: 77.39130401611328%\n",
      "precision of the model on thevalidationdata: 55.275081634521484%\n",
      "Epoch [24/500],step[4000] Loss:0.5675\n",
      "precision of the model on thetrainingdata: 64.22764587402344%\n",
      "precision of the model on thevalidationdata: 53.082794189453125%\n",
      "Epoch [30/500],step[5000] Loss:0.5731\n",
      "precision of the model on thetrainingdata: 66.07142639160156%\n",
      "precision of the model on thevalidationdata: 50.85183334350586%\n",
      "Epoch [36/500],step[6000] Loss:0.5049\n",
      "precision of the model on thetrainingdata: 73.72881317138672%\n",
      "precision of the model on thevalidationdata: 53.068687438964844%\n",
      "Epoch [42/500],step[7000] Loss:0.4380\n",
      "precision of the model on thetrainingdata: 77.0114974975586%\n",
      "precision of the model on thevalidationdata: 53.402366638183594%\n",
      "Epoch [48/500],step[8000] Loss:0.3722\n",
      "precision of the model on thetrainingdata: 84.03361511230469%\n",
      "precision of the model on thevalidationdata: 53.283226013183594%\n",
      "Epoch [54/500],step[9000] Loss:0.2996\n",
      "precision of the model on thetrainingdata: 89.47368621826172%\n",
      "precision of the model on thevalidationdata: 54.70888137817383%\n",
      "Epoch [60/500],step[10000] Loss:0.2746\n",
      "precision of the model on thetrainingdata: 93.80531311035156%\n",
      "precision of the model on thevalidationdata: 55.374244689941406%\n",
      "Epoch [66/500],step[11000] Loss:0.1673\n",
      "precision of the model on thetrainingdata: 95.0%\n",
      "precision of the model on thevalidationdata: 54.96971130371094%\n",
      "Epoch [72/500],step[12000] Loss:0.2347\n",
      "precision of the model on thetrainingdata: 95.76271057128906%\n",
      "precision of the model on thevalidationdata: 55.956485748291016%\n",
      "Epoch [78/500],step[13000] Loss:0.2634\n",
      "precision of the model on thetrainingdata: 90.43478393554688%\n",
      "precision of the model on thevalidationdata: 54.10182189941406%\n",
      "Epoch [84/500],step[14000] Loss:0.1516\n",
      "precision of the model on thetrainingdata: 86.53845977783203%\n",
      "precision of the model on thevalidationdata: 53.05596923828125%\n",
      "Epoch [90/500],step[15000] Loss:0.1016\n",
      "precision of the model on thetrainingdata: 96.12403106689453%\n",
      "precision of the model on thevalidationdata: 54.591835021972656%\n",
      "Epoch [96/500],step[16000] Loss:0.1042\n",
      "precision of the model on thetrainingdata: 95.7983169555664%\n",
      "precision of the model on thevalidationdata: 54.8947639465332%\n",
      "Epoch [102/500],step[17000] Loss:0.1050\n",
      "precision of the model on thetrainingdata: 93.69369506835938%\n",
      "precision of the model on thevalidationdata: 51.98183822631836%\n",
      "Epoch [108/500],step[18000] Loss:0.0857\n",
      "precision of the model on thetrainingdata: 96.63865661621094%\n",
      "precision of the model on thevalidationdata: 51.349422454833984%\n",
      "Epoch [114/500],step[19000] Loss:0.1383\n",
      "precision of the model on thetrainingdata: 93.45794677734375%\n",
      "precision of the model on thevalidationdata: 55.385684967041016%\n",
      "Epoch [120/500],step[20000] Loss:0.0756\n",
      "precision of the model on thetrainingdata: 94.69696807861328%\n",
      "precision of the model on thevalidationdata: 51.494972229003906%\n",
      "Epoch [126/500],step[21000] Loss:0.0800\n",
      "precision of the model on thetrainingdata: 94.59459686279297%\n",
      "precision of the model on thevalidationdata: 53.58433151245117%\n",
      "Epoch [132/500],step[22000] Loss:0.0820\n",
      "precision of the model on thetrainingdata: 97.5%\n",
      "precision of the model on thevalidationdata: 51.183719635009766%\n",
      "Epoch [138/500],step[23000] Loss:0.0633\n",
      "precision of the model on thetrainingdata: 95.90164184570312%\n",
      "precision of the model on thevalidationdata: 49.02766418457031%\n",
      "Epoch [144/500],step[24000] Loss:0.0861\n",
      "precision of the model on thetrainingdata: 95.412841796875%\n",
      "precision of the model on thevalidationdata: 54.452728271484375%\n",
      "Epoch [150/500],step[25000] Loss:0.0661\n",
      "precision of the model on thetrainingdata: 95.9349594116211%\n",
      "precision of the model on thevalidationdata: 50.98292541503906%\n",
      "Epoch [156/500],step[26000] Loss:0.1140\n",
      "precision of the model on thetrainingdata: 97.58064270019531%\n",
      "precision of the model on thevalidationdata: 52.123878479003906%\n",
      "Epoch [162/500],step[27000] Loss:0.0554\n",
      "precision of the model on thetrainingdata: 98.26087188720703%\n",
      "precision of the model on thevalidationdata: 52.54426956176758%\n",
      "Epoch [168/500],step[28000] Loss:0.0816\n",
      "precision of the model on thetrainingdata: 97.39130401611328%\n",
      "precision of the model on thevalidationdata: 52.41700744628906%\n",
      "Epoch [174/500],step[29000] Loss:0.2957\n",
      "precision of the model on thetrainingdata: 95.5752182006836%\n",
      "precision of the model on thevalidationdata: 52.18930435180664%\n",
      "Epoch [180/500],step[30000] Loss:0.0450\n",
      "precision of the model on thetrainingdata: 97.43589782714844%\n",
      "precision of the model on thevalidationdata: 52.008995056152344%\n",
      "Epoch [186/500],step[31000] Loss:0.0700\n",
      "precision of the model on thetrainingdata: 99.15966033935547%\n",
      "precision of the model on thevalidationdata: 51.025089263916016%\n",
      "Epoch [192/500],step[32000] Loss:0.1323\n",
      "precision of the model on thetrainingdata: 95.37036895751953%\n",
      "precision of the model on thevalidationdata: 50.61318588256836%\n",
      "Epoch [198/500],step[33000] Loss:0.0714\n",
      "precision of the model on thetrainingdata: 97.52066040039062%\n",
      "precision of the model on thevalidationdata: 52.3978385925293%\n",
      "Epoch [204/500],step[34000] Loss:0.0609\n",
      "precision of the model on thetrainingdata: 96.61016845703125%\n",
      "precision of the model on thevalidationdata: 54.42327117919922%\n",
      "Epoch [210/500],step[35000] Loss:0.0517\n",
      "precision of the model on thetrainingdata: 99.21260070800781%\n",
      "precision of the model on thevalidationdata: 53.5848274230957%\n",
      "Epoch [216/500],step[36000] Loss:0.0821\n",
      "precision of the model on thetrainingdata: 99.15254211425781%\n",
      "precision of the model on thevalidationdata: 52.47356414794922%\n",
      "Epoch [222/500],step[37000] Loss:0.0534\n",
      "precision of the model on thetrainingdata: 98.4375%\n",
      "precision of the model on thevalidationdata: 52.371620178222656%\n",
      "Epoch [228/500],step[38000] Loss:0.0478\n",
      "precision of the model on thetrainingdata: 98.30508422851562%\n",
      "precision of the model on thevalidationdata: 51.076114654541016%\n",
      "Epoch [234/500],step[39000] Loss:0.0263\n",
      "precision of the model on thetrainingdata: 98.4126968383789%\n",
      "precision of the model on thevalidationdata: 50.53418731689453%\n",
      "Epoch [240/500],step[40000] Loss:0.1559\n",
      "precision of the model on thetrainingdata: 93.12976837158203%\n",
      "precision of the model on thevalidationdata: 49.968589782714844%\n",
      "Epoch [246/500],step[41000] Loss:0.0371\n",
      "precision of the model on thetrainingdata: 99.19355010986328%\n",
      "precision of the model on thevalidationdata: 50.396766662597656%\n",
      "Epoch [252/500],step[42000] Loss:0.1106\n",
      "precision of the model on thetrainingdata: 97.54098510742188%\n",
      "precision of the model on thevalidationdata: 50.4301872253418%\n",
      "Epoch [258/500],step[43000] Loss:0.0484\n",
      "precision of the model on thetrainingdata: 95.08197021484375%\n",
      "precision of the model on thevalidationdata: 50.62785339355469%\n",
      "Epoch [264/500],step[44000] Loss:0.0383\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 52.55946731567383%\n",
      "Epoch [270/500],step[45000] Loss:0.0324\n",
      "precision of the model on thetrainingdata: 99.17355346679688%\n",
      "precision of the model on thevalidationdata: 52.20291519165039%\n",
      "Epoch [276/500],step[46000] Loss:0.0319\n",
      "precision of the model on thetrainingdata: 98.46154022216797%\n",
      "precision of the model on thevalidationdata: 50.95649719238281%\n",
      "Epoch [282/500],step[47000] Loss:0.1011\n",
      "precision of the model on thetrainingdata: 96.7213134765625%\n",
      "precision of the model on thevalidationdata: 51.20244216918945%\n",
      "Epoch [288/500],step[48000] Loss:0.0559\n",
      "precision of the model on thetrainingdata: 95.04132080078125%\n",
      "precision of the model on thevalidationdata: 50.26766586303711%\n",
      "Epoch [294/500],step[49000] Loss:0.0520\n",
      "precision of the model on thetrainingdata: 98.31932830810547%\n",
      "precision of the model on thevalidationdata: 50.62611770629883%\n",
      "Epoch [300/500],step[50000] Loss:0.0284\n",
      "precision of the model on thetrainingdata: 99.21260070800781%\n",
      "precision of the model on thevalidationdata: 50.30404281616211%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [306/500],step[51000] Loss:0.0363\n",
      "precision of the model on thetrainingdata: 98.29059600830078%\n",
      "precision of the model on thevalidationdata: 53.587730407714844%\n",
      "Epoch [312/500],step[52000] Loss:0.0104\n",
      "precision of the model on thetrainingdata: 99.13043212890625%\n",
      "precision of the model on thevalidationdata: 53.670692443847656%\n",
      "Epoch [318/500],step[53000] Loss:0.0804\n",
      "precision of the model on thetrainingdata: 96.94656372070312%\n",
      "precision of the model on thevalidationdata: 51.96696853637695%\n",
      "Epoch [324/500],step[54000] Loss:0.0292\n",
      "precision of the model on thetrainingdata: 98.37398529052734%\n",
      "precision of the model on thevalidationdata: 52.42360305786133%\n",
      "Epoch [330/500],step[55000] Loss:0.0168\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 52.1324348449707%\n",
      "Epoch [336/500],step[56000] Loss:0.0287\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 52.08187484741211%\n",
      "Epoch [342/500],step[57000] Loss:0.0376\n",
      "precision of the model on thetrainingdata: 97.5%\n",
      "precision of the model on thevalidationdata: 49.71091079711914%\n",
      "Epoch [348/500],step[58000] Loss:0.0528\n",
      "precision of the model on thetrainingdata: 98.19819641113281%\n",
      "precision of the model on thevalidationdata: 51.427406311035156%\n",
      "Epoch [354/500],step[59000] Loss:0.0140\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 53.72919845581055%\n",
      "Epoch [360/500],step[60000] Loss:0.0163\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 50.91716766357422%\n",
      "Epoch [366/500],step[61000] Loss:0.0391\n",
      "precision of the model on thetrainingdata: 96.82539367675781%\n",
      "precision of the model on thevalidationdata: 50.90103530883789%\n",
      "Epoch [372/500],step[62000] Loss:0.0246\n",
      "precision of the model on thetrainingdata: 98.47328186035156%\n",
      "precision of the model on thevalidationdata: 50.93476867675781%\n",
      "Epoch [378/500],step[63000] Loss:0.0466\n",
      "precision of the model on thetrainingdata: 99.16666412353516%\n",
      "precision of the model on thevalidationdata: 53.18290328979492%\n",
      "Epoch [384/500],step[64000] Loss:0.0595\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 50.79658508300781%\n",
      "Epoch [390/500],step[65000] Loss:0.0179\n",
      "precision of the model on thetrainingdata: 98.13084411621094%\n",
      "precision of the model on thevalidationdata: 51.57154083251953%\n",
      "Epoch [396/500],step[66000] Loss:0.2145\n",
      "precision of the model on thetrainingdata: 97.52066040039062%\n",
      "precision of the model on thevalidationdata: 53.875022888183594%\n",
      "Epoch [402/500],step[67000] Loss:0.0105\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 50.75625228881836%\n",
      "Epoch [408/500],step[68000] Loss:0.2725\n",
      "precision of the model on thetrainingdata: 94.01709747314453%\n",
      "precision of the model on thevalidationdata: 50.52631759643555%\n",
      "Epoch [414/500],step[69000] Loss:0.0281\n",
      "precision of the model on thetrainingdata: 97.2727279663086%\n",
      "precision of the model on thevalidationdata: 51.1701545715332%\n",
      "Epoch [420/500],step[70000] Loss:0.0382\n",
      "precision of the model on thetrainingdata: 98.31932830810547%\n",
      "precision of the model on thevalidationdata: 50.918846130371094%\n",
      "Epoch [426/500],step[71000] Loss:0.0283\n",
      "precision of the model on thetrainingdata: 99.22480773925781%\n",
      "precision of the model on thevalidationdata: 50.5569953918457%\n",
      "Epoch [432/500],step[72000] Loss:0.0182\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 52.34456253051758%\n",
      "Epoch [438/500],step[73000] Loss:0.1845\n",
      "precision of the model on thetrainingdata: 96.2686538696289%\n",
      "precision of the model on thevalidationdata: 50.37471008300781%\n",
      "Epoch [444/500],step[74000] Loss:0.0088\n",
      "precision of the model on thetrainingdata: 99.14530181884766%\n",
      "precision of the model on thevalidationdata: 52.8988037109375%\n",
      "Epoch [450/500],step[75000] Loss:0.0179\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 52.58075714111328%\n",
      "Epoch [456/500],step[76000] Loss:0.0205\n",
      "precision of the model on thetrainingdata: 97.7443618774414%\n",
      "precision of the model on thevalidationdata: 51.95859146118164%\n",
      "Epoch [462/500],step[77000] Loss:0.0189\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 50.52976608276367%\n",
      "Epoch [468/500],step[78000] Loss:0.0254\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 52.60817337036133%\n",
      "Epoch [474/500],step[79000] Loss:0.0180\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 52.07487106323242%\n",
      "Epoch [480/500],step[80000] Loss:0.0271\n",
      "precision of the model on thetrainingdata: 99.19999694824219%\n",
      "precision of the model on thevalidationdata: 51.55765151977539%\n",
      "Epoch [486/500],step[81000] Loss:0.0531\n",
      "precision of the model on thetrainingdata: 98.33333587646484%\n",
      "precision of the model on thevalidationdata: 50.808082580566406%\n",
      "Epoch [492/500],step[82000] Loss:0.0179\n",
      "precision of the model on thetrainingdata: 98.56114959716797%\n",
      "precision of the model on thevalidationdata: 50.53061294555664%\n",
      "Epoch [498/500],step[83000] Loss:0.1420\n",
      "precision of the model on thetrainingdata: 99.13043212890625%\n",
      "precision of the model on thevalidationdata: 50.42609405517578%\n"
     ]
    }
   ],
   "source": [
    "#训练过程\n",
    "for epoch in range(num_epochs):\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images=images.type(torch.FloatTensor)\n",
    "        labels=labels.type(torch.FloatTensor)\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        #forward pass\n",
    "        outputs=lstm(images)\n",
    "        loss=loss_function(outputs,labels.long())\n",
    "        \n",
    "        #Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_step+=1\n",
    "        if (total_step)%1000==0:#each 10 iterations is one epoch\n",
    "            print(\"Epoch [{}/{}],step[{}] Loss:{:.4f}\".format(epoch+1,num_epochs,total_step,loss.item()))\n",
    "            _,train_pre=predict_precision(lstm,images,labels,device,predict_type='training')\n",
    "            lstm_train_precision.append(train_pre)\n",
    "            for images, labels in valid_loader:\n",
    "                _,valid_pre=predict_precision(lstm,images,labels,device,predict_type='validation')\n",
    "            lstm_valid_precision.append(valid_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建CONV1D-LSTM Model (Many-to-One)\n",
    "class CONV1D_LSTM(nn.Module):\n",
    "    def __init__(self ,in_channel,out_channel, hidden_size, num_layers, num_classes,device=torch.device(\"cuda:1\")):\n",
    "        super(CONV1D_LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channel, out_channels=out_channel,kernel_size=1, stride=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channel)\n",
    "        self.conv2 = nn.Conv1d(in_channels=out_channel, out_channels=out_channel,kernel_size=1, stride=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channel)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.lstm = nn.LSTM(out_channel, hidden_size, num_layers, batch_first=True)  # batch_first=True仅仅针对输入而言\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight.to(device), mode='fan_out', nonlinearity='relu')\n",
    "                   \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #forward prop\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out=torch.transpose(out,2,1)\n",
    "        #因为pytorch里lstm和conv1d的input sequence位置不一样，需要调整。\n",
    "        \n",
    "        # 设置初始状态h_0与c_0的状态是初始的状态，一般设置为0，尺寸是,x.size(0)\n",
    "        h0 = Variable(torch.zeros(self.num_layers, out.size(0), self.hidden_size)).to(device)\n",
    "        c0 = Variable(torch.zeros(self.num_layers, out.size(0), self.hidden_size)).to(device)\n",
    "\n",
    "        # Forward propagate RNN\n",
    "        out, (h_n, c_n) = self.lstm(out, (h0, c0))  # 送入一个初始的x值，作为输入以及(h0, c0)\n",
    "\n",
    "        # Decode hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])  # output也是batch_first, 实际上h_n与c_n并不是batch_first\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Hyper Parameters\n",
    "    sequence_length = 10  # 序列长度，将图像的每一列作为一个序列\n",
    "    in_channel = 42\n",
    "    out_channel=64\n",
    "    hidden_size = 64  # 隐藏层的size\n",
    "    num_layers =  4 # 有多少层\n",
    "\n",
    "    num_classes = 2\n",
    "    batch_size = 256\n",
    "    num_epochs = 500\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    device = torch.device(\"cuda:1\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CONV1D_LSTM(\n",
       "  (conv1): Conv1d(42, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): LeakyReLU(negative_slope=0.01)\n",
       "  (lstm): LSTM(64, 64, num_layers=4, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1d_lstm = CONV1D_LSTM(in_channel=in_channel, out_channel=out_channel,\n",
    "                   hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes,device=device)\n",
    "conv1d_lstm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(conv1d_lstm.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=np.transpose(train_data,(0,2,1))\n",
    "valid_data=np.transpose(valid_data,(0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=GetLoader(train_data,train_label)\n",
    "valid=GetLoader(valid_data,valid_label)\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train,batch_size=batch_size,shuffle=True,num_workers=0)\n",
    "valid_loader=torch.utils.data.DataLoader(dataset=valid,batch_size=valid_data.shape[0],shuffle=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step=0\n",
    "conv1dlstm_train_precision=[]\n",
    "conv1dlstm_valid_precision=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/500],step[1000] Loss:0.6282\n",
      "precision of the model on thetrainingdata: 63.33333206176758%\n",
      "precision of the model on thevalidationdata: 50.737266540527344%\n",
      "Epoch [12/500],step[2000] Loss:0.5522\n",
      "precision of the model on thetrainingdata: 67.93893432617188%\n",
      "precision of the model on thevalidationdata: 50.680870056152344%\n",
      "Epoch [18/500],step[3000] Loss:0.5940\n",
      "precision of the model on thetrainingdata: 59.52381134033203%\n",
      "precision of the model on thevalidationdata: 50.983238220214844%\n",
      "Epoch [24/500],step[4000] Loss:0.5562\n",
      "precision of the model on thetrainingdata: 62.99212646484375%\n",
      "precision of the model on thevalidationdata: 51.35469436645508%\n",
      "Epoch [30/500],step[5000] Loss:0.5750\n",
      "precision of the model on thetrainingdata: 61.78861618041992%\n",
      "precision of the model on thevalidationdata: 52.436851501464844%\n",
      "Epoch [36/500],step[6000] Loss:0.5253\n",
      "precision of the model on thetrainingdata: 71.64179229736328%\n",
      "precision of the model on thevalidationdata: 52.995452880859375%\n",
      "Epoch [42/500],step[7000] Loss:0.4772\n",
      "precision of the model on thetrainingdata: 72.22222137451172%\n",
      "precision of the model on thevalidationdata: 53.44160842895508%\n",
      "Epoch [48/500],step[8000] Loss:0.5259\n",
      "precision of the model on thetrainingdata: 74.79674530029297%\n",
      "precision of the model on thevalidationdata: 52.26213836669922%\n",
      "Epoch [54/500],step[9000] Loss:0.3455\n",
      "precision of the model on thetrainingdata: 79.4871826171875%\n",
      "precision of the model on thevalidationdata: 52.68718338012695%\n",
      "Epoch [60/500],step[10000] Loss:0.2523\n",
      "precision of the model on thetrainingdata: 70.49180603027344%\n",
      "precision of the model on thevalidationdata: 53.090850830078125%\n",
      "Epoch [66/500],step[11000] Loss:0.2355\n",
      "precision of the model on thetrainingdata: 73.39449310302734%\n",
      "precision of the model on thevalidationdata: 53.92241287231445%\n",
      "Epoch [72/500],step[12000] Loss:0.1479\n",
      "precision of the model on thetrainingdata: 85.9504165649414%\n",
      "precision of the model on thevalidationdata: 54.02796173095703%\n",
      "Epoch [78/500],step[13000] Loss:0.1415\n",
      "precision of the model on thetrainingdata: 89.62963104248047%\n",
      "precision of the model on thevalidationdata: 53.210609436035156%\n",
      "Epoch [84/500],step[14000] Loss:0.2007\n",
      "precision of the model on thetrainingdata: 90.76923370361328%\n",
      "precision of the model on thevalidationdata: 52.931373596191406%\n",
      "Epoch [90/500],step[15000] Loss:0.1022\n",
      "precision of the model on thetrainingdata: 91.36690521240234%\n",
      "precision of the model on thevalidationdata: 52.064605712890625%\n",
      "Epoch [96/500],step[16000] Loss:0.0620\n",
      "precision of the model on thetrainingdata: 92.56198120117188%\n",
      "precision of the model on thevalidationdata: 51.96704864501953%\n",
      "Epoch [102/500],step[17000] Loss:0.0768\n",
      "precision of the model on thetrainingdata: 90.51724243164062%\n",
      "precision of the model on thevalidationdata: 51.836856842041016%\n",
      "Epoch [108/500],step[18000] Loss:0.1380\n",
      "precision of the model on thetrainingdata: 82.17053985595703%\n",
      "precision of the model on thevalidationdata: 54.40129470825195%\n",
      "Epoch [114/500],step[19000] Loss:0.1013\n",
      "precision of the model on thetrainingdata: 77.31092071533203%\n",
      "precision of the model on thevalidationdata: 51.50029754638672%\n",
      "Epoch [120/500],step[20000] Loss:0.0714\n",
      "precision of the model on thetrainingdata: 86.5671615600586%\n",
      "precision of the model on thevalidationdata: 51.64772033691406%\n",
      "Epoch [126/500],step[21000] Loss:0.0369\n",
      "precision of the model on thetrainingdata: 80.95237731933594%\n",
      "precision of the model on thevalidationdata: 51.96241760253906%\n",
      "Epoch [132/500],step[22000] Loss:0.0326\n",
      "precision of the model on thetrainingdata: 94.7368392944336%\n",
      "precision of the model on thevalidationdata: 54.577091217041016%\n",
      "Epoch [138/500],step[23000] Loss:0.0451\n",
      "precision of the model on thetrainingdata: 99.21260070800781%\n",
      "precision of the model on thevalidationdata: 53.132286071777344%\n",
      "Epoch [144/500],step[24000] Loss:0.0258\n",
      "precision of the model on thetrainingdata: 85.84906005859375%\n",
      "precision of the model on thevalidationdata: 52.39216995239258%\n",
      "Epoch [150/500],step[25000] Loss:0.0335\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 53.187156677246094%\n",
      "Epoch [156/500],step[26000] Loss:0.0591\n",
      "precision of the model on thetrainingdata: 92.80000305175781%\n",
      "precision of the model on thevalidationdata: 54.34984588623047%\n",
      "Epoch [162/500],step[27000] Loss:0.0320\n",
      "precision of the model on thetrainingdata: 72.65625%\n",
      "precision of the model on thevalidationdata: 55.32810592651367%\n",
      "Epoch [168/500],step[28000] Loss:0.0455\n",
      "precision of the model on thetrainingdata: 90.32257843017578%\n",
      "precision of the model on thevalidationdata: 54.188743591308594%\n",
      "Epoch [174/500],step[29000] Loss:0.0164\n",
      "precision of the model on thetrainingdata: 80.35713958740234%\n",
      "precision of the model on thevalidationdata: 53.883750915527344%\n",
      "Epoch [180/500],step[30000] Loss:0.0148\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 52.56829071044922%\n",
      "Epoch [186/500],step[31000] Loss:0.0671\n",
      "precision of the model on thetrainingdata: 98.4962387084961%\n",
      "precision of the model on thevalidationdata: 53.15763473510742%\n",
      "Epoch [192/500],step[32000] Loss:0.0456\n",
      "precision of the model on thetrainingdata: 99.16666412353516%\n",
      "precision of the model on thevalidationdata: 53.65492630004883%\n",
      "Epoch [198/500],step[33000] Loss:0.1056\n",
      "precision of the model on thetrainingdata: 97.29729461669922%\n",
      "precision of the model on thevalidationdata: 52.08395767211914%\n",
      "Epoch [204/500],step[34000] Loss:0.0066\n",
      "precision of the model on thetrainingdata: 90.65420532226562%\n",
      "precision of the model on thevalidationdata: 54.064117431640625%\n",
      "Epoch [210/500],step[35000] Loss:0.0099\n",
      "precision of the model on thetrainingdata: 97.03704071044922%\n",
      "precision of the model on thevalidationdata: 54.15179443359375%\n",
      "Epoch [216/500],step[36000] Loss:0.0327\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 51.932579040527344%\n",
      "Epoch [222/500],step[37000] Loss:0.0098\n",
      "precision of the model on thetrainingdata: 97.45762634277344%\n",
      "precision of the model on thevalidationdata: 54.596534729003906%\n",
      "Epoch [228/500],step[38000] Loss:0.0108\n",
      "precision of the model on thetrainingdata: 99.23664093017578%\n",
      "precision of the model on thevalidationdata: 52.63951873779297%\n",
      "Epoch [234/500],step[39000] Loss:0.0093\n",
      "precision of the model on thetrainingdata: 98.31932830810547%\n",
      "precision of the model on thevalidationdata: 52.66297912597656%\n",
      "Epoch [240/500],step[40000] Loss:0.0455\n",
      "precision of the model on thetrainingdata: 98.24561309814453%\n",
      "precision of the model on thevalidationdata: 54.54697036743164%\n",
      "Epoch [246/500],step[41000] Loss:0.0419\n",
      "precision of the model on thetrainingdata: 99.08256530761719%\n",
      "precision of the model on thevalidationdata: 52.20682907104492%\n",
      "Epoch [252/500],step[42000] Loss:0.0310\n",
      "precision of the model on thetrainingdata: 96.15384674072266%\n",
      "precision of the model on thevalidationdata: 54.73033905029297%\n",
      "Epoch [258/500],step[43000] Loss:0.0250\n",
      "precision of the model on thetrainingdata: 95.96774291992188%\n",
      "precision of the model on thevalidationdata: 52.591529846191406%\n",
      "Epoch [264/500],step[44000] Loss:0.0024\n",
      "precision of the model on thetrainingdata: 98.07691955566406%\n",
      "precision of the model on thevalidationdata: 53.531028747558594%\n",
      "Epoch [270/500],step[45000] Loss:0.0716\n",
      "precision of the model on thetrainingdata: 80.3149642944336%\n",
      "precision of the model on thevalidationdata: 52.53718185424805%\n",
      "Epoch [276/500],step[46000] Loss:0.0061\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 52.32179641723633%\n",
      "Epoch [282/500],step[47000] Loss:0.0330\n",
      "precision of the model on thetrainingdata: 92.481201171875%\n",
      "precision of the model on thevalidationdata: 54.61491394042969%\n",
      "Epoch [288/500],step[48000] Loss:0.0079\n",
      "precision of the model on thetrainingdata: 98.31932830810547%\n",
      "precision of the model on thevalidationdata: 52.78248977661133%\n",
      "Epoch [294/500],step[49000] Loss:0.0152\n",
      "precision of the model on thetrainingdata: 98.29059600830078%\n",
      "precision of the model on thevalidationdata: 53.41979217529297%\n",
      "Epoch [300/500],step[50000] Loss:0.0174\n",
      "precision of the model on thetrainingdata: 98.18181610107422%\n",
      "precision of the model on thevalidationdata: 52.85072708129883%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [306/500],step[51000] Loss:0.0210\n",
      "precision of the model on thetrainingdata: 97.5999984741211%\n",
      "precision of the model on thevalidationdata: 52.68785858154297%\n",
      "Epoch [312/500],step[52000] Loss:0.0278\n",
      "precision of the model on thetrainingdata: 97.902099609375%\n",
      "precision of the model on thevalidationdata: 52.41251754760742%\n",
      "Epoch [318/500],step[53000] Loss:0.0683\n",
      "precision of the model on thetrainingdata: 86.44068145751953%\n",
      "precision of the model on thevalidationdata: 55.21620178222656%\n",
      "Epoch [324/500],step[54000] Loss:0.0151\n",
      "precision of the model on thetrainingdata: 95.96774291992188%\n",
      "precision of the model on thevalidationdata: 53.62884521484375%\n",
      "Epoch [330/500],step[55000] Loss:0.0284\n",
      "precision of the model on thetrainingdata: 98.13084411621094%\n",
      "precision of the model on thevalidationdata: 52.64915084838867%\n",
      "Epoch [336/500],step[56000] Loss:0.0068\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 52.2328987121582%\n",
      "Epoch [342/500],step[57000] Loss:0.0437\n",
      "precision of the model on thetrainingdata: 80.34188079833984%\n",
      "precision of the model on thevalidationdata: 54.84423065185547%\n",
      "Epoch [348/500],step[58000] Loss:0.0083\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 53.499244689941406%\n",
      "Epoch [354/500],step[59000] Loss:0.0268\n",
      "precision of the model on thetrainingdata: 97.39130401611328%\n",
      "precision of the model on thevalidationdata: 52.6159782409668%\n",
      "Epoch [360/500],step[60000] Loss:0.0083\n",
      "precision of the model on thetrainingdata: 86.32478332519531%\n",
      "precision of the model on thevalidationdata: 53.46094512939453%\n",
      "Epoch [366/500],step[61000] Loss:0.0728\n",
      "precision of the model on thetrainingdata: 96.06299591064453%\n",
      "precision of the model on thevalidationdata: 53.22649383544922%\n",
      "Epoch [372/500],step[62000] Loss:0.0590\n",
      "precision of the model on thetrainingdata: 97.5%\n",
      "precision of the model on thevalidationdata: 52.722347259521484%\n",
      "Epoch [378/500],step[63000] Loss:0.0054\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 53.58231735229492%\n",
      "Epoch [384/500],step[64000] Loss:0.0229\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 53.24207305908203%\n",
      "Epoch [390/500],step[65000] Loss:0.0288\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 52.685890197753906%\n",
      "Epoch [396/500],step[66000] Loss:0.0042\n",
      "precision of the model on thetrainingdata: 99.23664093017578%\n",
      "precision of the model on thevalidationdata: 52.859989166259766%\n",
      "Epoch [402/500],step[67000] Loss:0.0067\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 53.26520919799805%\n",
      "Epoch [408/500],step[68000] Loss:0.0130\n",
      "precision of the model on thetrainingdata: 99.15966033935547%\n",
      "precision of the model on thevalidationdata: 52.943702697753906%\n",
      "Epoch [414/500],step[69000] Loss:0.0223\n",
      "precision of the model on thetrainingdata: 99.15254211425781%\n",
      "precision of the model on thevalidationdata: 52.057403564453125%\n",
      "Epoch [420/500],step[70000] Loss:0.0287\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 52.40054702758789%\n",
      "Epoch [426/500],step[71000] Loss:0.0053\n",
      "precision of the model on thetrainingdata: 98.38710021972656%\n",
      "precision of the model on thevalidationdata: 53.500370025634766%\n",
      "Epoch [432/500],step[72000] Loss:0.0030\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 52.988521575927734%\n",
      "Epoch [438/500],step[73000] Loss:0.0432\n",
      "precision of the model on thetrainingdata: 97.2727279663086%\n",
      "precision of the model on thevalidationdata: 53.18775939941406%\n",
      "Epoch [444/500],step[74000] Loss:0.0048\n",
      "precision of the model on thetrainingdata: 97.6744155883789%\n",
      "precision of the model on thevalidationdata: 52.76210403442383%\n",
      "Epoch [450/500],step[75000] Loss:0.0469\n",
      "precision of the model on thetrainingdata: 99.20635223388672%\n",
      "precision of the model on thevalidationdata: 53.97934341430664%\n",
      "Epoch [456/500],step[76000] Loss:0.0091\n",
      "precision of the model on thetrainingdata: 92.79279327392578%\n",
      "precision of the model on thevalidationdata: 54.10717010498047%\n",
      "Epoch [462/500],step[77000] Loss:0.0047\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 52.486026763916016%\n",
      "Epoch [468/500],step[78000] Loss:0.0054\n",
      "precision of the model on thetrainingdata: 96.85039520263672%\n",
      "precision of the model on thevalidationdata: 54.598289489746094%\n",
      "Epoch [474/500],step[79000] Loss:0.0160\n",
      "precision of the model on thetrainingdata: 100.0%\n",
      "precision of the model on thevalidationdata: 52.49079132080078%\n",
      "Epoch [480/500],step[80000] Loss:0.0195\n",
      "precision of the model on thetrainingdata: 96.6942138671875%\n",
      "precision of the model on thevalidationdata: 53.602474212646484%\n",
      "Epoch [486/500],step[81000] Loss:0.0516\n",
      "precision of the model on thetrainingdata: 89.7196273803711%\n",
      "precision of the model on thevalidationdata: 54.28129196166992%\n",
      "Epoch [492/500],step[82000] Loss:0.1560\n",
      "precision of the model on thetrainingdata: 86.77686309814453%\n",
      "precision of the model on thevalidationdata: 54.497352600097656%\n",
      "Epoch [498/500],step[83000] Loss:0.0054\n",
      "precision of the model on thetrainingdata: 97.32142639160156%\n",
      "precision of the model on thevalidationdata: 52.23015213012695%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images=images.type(torch.FloatTensor)\n",
    "        labels=labels.type(torch.FloatTensor)\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        #forward pass\n",
    "        outputs=conv1d_lstm(images)\n",
    "        loss=loss_function(outputs,labels.long())\n",
    "        \n",
    "        #Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_step+=1\n",
    "        if (total_step)%1000==0:\n",
    "            print(\"Epoch [{}/{}],step[{}] Loss:{:.4f}\".format(epoch+1,num_epochs,total_step,loss.item()))\n",
    "            _,train_pre=predict_precision(conv1d_lstm,images,labels,device,predict_type='training')\n",
    "            conv1dlstm_train_precision.append(train_pre)\n",
    "            for images, labels in valid_loader:\n",
    "                _,valid_pre=predict_precision(conv1d_lstm,images,labels,device,predict_type='validation')\n",
    "            conv1dlstm_valid_precision.append(valid_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_train_=pd.Series(np.array(lstm_train_precision).astype('float32'))\n",
    "lstm_valid_=pd.Series(np.array(lstm_valid_precision).astype('float32'))\n",
    "convlstm_train_=pd.Series(np.array(conv1dlstm_train_precision).astype('float32'))\n",
    "convlstm_valid_=pd.Series(np.array(conv1dlstm_valid_precision).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7814648697721939"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_train_.corr(convlstm_train_)#train集precision相关性系数为0.7814648697721939"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.23722368976954009"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convlstm_valid_.corr(lstm_valid_)#valid集precision相关性系数为-0.23722368976954009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv1D_LSTM trial 6 总结:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
