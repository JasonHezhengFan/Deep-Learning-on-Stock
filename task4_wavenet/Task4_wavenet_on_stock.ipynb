{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from classification_models import GetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalConv1d(nn.Conv1d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=2, stride=1,\n",
    "                 padding=1, dilation=1, groups=1, bias=False):\n",
    "        super(CausalConv1d, self).__init__(in_channels, out_channels, kernel_size, stride,\n",
    "                                           padding, dilation, groups, bias)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        outputs = super(CausalConv1d, self).forward(inputs)\n",
    "        return outputs[:,:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DilatedConv1d(nn.Conv1d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=2, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=False):\n",
    "        super(DilatedConv1d, self).__init__(in_channels, out_channels, kernel_size, stride,\n",
    "                                            padding, dilation, groups, bias)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        outputs = super(DilatedConv1d, self).forward(inputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, res_channels, skip_channels, dilation):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.filter_conv = DilatedConv1d(in_channels=res_channels, out_channels=res_channels, dilation=dilation)\n",
    "        self.gate_conv = DilatedConv1d(in_channels=res_channels, out_channels=res_channels, dilation=dilation)\n",
    "        self.skip_conv = nn.Conv1d(in_channels=res_channels, out_channels=skip_channels, kernel_size=1)\n",
    "        self.residual_conv = nn.Conv1d(in_channels=res_channels, out_channels=res_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        #print(dilation)\n",
    "        sigmoid_out = torch.sigmoid(self.gate_conv(inputs))\n",
    "        tahn_out = torch.tanh(self.filter_conv(inputs))\n",
    "        output = sigmoid_out * tahn_out\n",
    "        #\n",
    "        skip_out = self.skip_conv(output)\n",
    "        res_out = self.residual_conv(output)\n",
    "        res_out = res_out + inputs[:, :, -res_out.size(2):]\n",
    "        # res\n",
    "        return res_out , skip_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveNet(nn.Module):\n",
    "    def __init__(self, num_classes, in_depth=128, in_channels=42, skip_channels=64, dilation_depth=7, device=torch.device(\"cpu\")):\n",
    "        super(WaveNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=32,\n",
    "                               kernel_size=2, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        self.dilations = [2**i for i in range(dilation_depth)]\n",
    "        self.main = nn.ModuleList([ResidualBlock(res_channels=32, \n",
    "                                                 skip_channels=skip_channels,dilation=dilation) for dilation in self.dilations])\n",
    "        #self.pre = nn.Embedding(in_depth, res_channels)\n",
    "        #self.pre_conv = CausalConv1d(in_channels=res_channels, out_channels=res_channels)\n",
    "        self.post = nn.Sequential(nn.ReLU(),\n",
    "                                  nn.Conv1d(skip_channels,skip_channels,1),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Conv1d(skip_channels,in_depth,kernel_size=1))\n",
    "        self.fc = nn.Linear(in_depth*2, num_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight.to(device), mode='fan_out', nonlinearity='relu')\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        #outputs = self.preprocess(inputs)\n",
    "        skip_connections = []\n",
    "        \n",
    "        outputs = self.conv1(inputs)\n",
    "        \n",
    "        for layer in self.main:\n",
    "            outputs,skip = layer(outputs)\n",
    "            skip_connections.append(skip)\n",
    "        #print(outputs.shape)\n",
    "        outputs = sum([s[:,:,-outputs.size(2):] for s in skip_connections])\n",
    "        #print(\"shape\")\n",
    "        outputs = self.post(outputs)\n",
    "        #print(outputs.shape)  \n",
    "        outputs = torch.flatten(outputs, 1)\n",
    "        #print(outputs.shape)\n",
    "        outputs = self.fc(outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_precision(model,images,labels,device,predict_type):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct=0\n",
    "        total=0\n",
    "        images=images.type(torch.FloatTensor)\n",
    "        labels=labels.type(torch.FloatTensor)\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs=model(images)\n",
    "        _,predicted=torch.max(outputs.data,1)\n",
    "        total+=sum(predicted)\n",
    "        correct+=(sum(predicted*labels))\n",
    "        print('precision of the model on the'+predict_type+'data: {}%'.format(100*correct/total))\n",
    "    model.train()\n",
    "    return predicted, 100*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入train数据\n",
    "a=np.load(\"train_data.npy\")\n",
    "b=a.reshape([a.shape[0],a.shape[1]*a.shape[2]])\n",
    "c=b[~np.isnan(b).any(axis=1),:]\n",
    "train_data=c.reshape([c.shape[0], a.shape[1],a.shape[2]])\n",
    "d=np.load(\"train_label.npy\").reshape(-1,1)\n",
    "train_label=d[~np.isnan(b).any(axis=1),:].reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入valid数据\n",
    "a=np.load(\"valid_data.npy\")\n",
    "b=a.reshape([a.shape[0],a.shape[1]*a.shape[2]])\n",
    "c=b[~np.isnan(b).any(axis=1),:]\n",
    "valid_data=c.reshape([c.shape[0], a.shape[1],a.shape[2]])\n",
    "d=np.load(\"valid_label.npy\").reshape(-1,1)\n",
    "valid_label=d[~np.isnan(b).any(axis=1),:].reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.transpose(train_data,(0,2,1))\n",
    "#train_data = train_data[:,:,0:9]\n",
    "valid_data = np.transpose(valid_data,(0,2,1)) \n",
    "#valid_data = valid_data[:,:,0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42531, 42, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wavenet trial 1: 尝试在旧的10日为sequence的数据上实验\n",
    "num_classes=2 \n",
    "in_depth=64 \n",
    "in_channels=42 \n",
    "skip_channels=32 \n",
    "dilation_depth=3 \n",
    "device= torch.device(\"cuda:1\")\n",
    "batch_size=128\n",
    "learning_rate=0.001\n",
    "num_epochs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=GetLoader(train_data,train_label)\n",
    "valid=GetLoader(valid_data,valid_label)\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train,batch_size=batch_size,shuffle=True,num_workers=0)\n",
    "valid_loader=torch.utils.data.DataLoader(dataset=valid,batch_size=valid_data.shape[0],shuffle=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WaveNet(\n",
       "  (conv1): Conv1d(42, 32, kernel_size=(2,), stride=(1,), padding=(1,), bias=False)\n",
       "  (main): ModuleList(\n",
       "    (0): ResidualBlock(\n",
       "      (filter_conv): DilatedConv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "      (gate_conv): DilatedConv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "      (skip_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "      (residual_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (filter_conv): DilatedConv1d(32, 32, kernel_size=(2,), stride=(1,), dilation=(2,), bias=False)\n",
       "      (gate_conv): DilatedConv1d(32, 32, kernel_size=(2,), stride=(1,), dilation=(2,), bias=False)\n",
       "      (skip_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "      (residual_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (filter_conv): DilatedConv1d(32, 32, kernel_size=(2,), stride=(1,), dilation=(4,), bias=False)\n",
       "      (gate_conv): DilatedConv1d(32, 32, kernel_size=(2,), stride=(1,), dilation=(4,), bias=False)\n",
       "      (skip_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "      (residual_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (post): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "    (2): ReLU()\n",
       "    (3): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavenet = WaveNet(num_classes, in_depth, in_channels, skip_channels, dilation_depth, device)\n",
    "wavenet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(wavenet.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step=0\n",
    "train_precision=[]\n",
    "valid_precision=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#训练过程\n",
    "for epoch in range(num_epochs):\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images=images.type(torch.FloatTensor)\n",
    "        labels=labels.type(torch.FloatTensor)\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        #forward pass\n",
    "        outputs=wavenet(images)\n",
    "        loss=loss_function(outputs,labels.long())\n",
    "        \n",
    "        #Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_step+=1\n",
    "        if (total_step)%1000==0:#each 10 iterations is one epoch\n",
    "            print(\"Epoch [{}/{}],step[{}] Loss:{:.4f}\".format(epoch+1,num_epochs,total_step,loss.item()))\n",
    "            _,train_pre=predict_precision(wavenet,images,labels,device,predict_type='training')\n",
    "            train_precision.append(train_pre)\n",
    "            for images, labels in valid_loader:\n",
    "                _,valid_pre=predict_precision(wavenet,images,labels,device,predict_type='validation')\n",
    "            valid_precision.append(valid_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in valid_loader:\n",
    "    images, labels = data\n",
    "    predict_precision(wavenet,images,labels,device,'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_precision,label=\"training precision\")\n",
    "plt.plot(valid_precision,label=\"validation precision\")\n",
    "plt.title(\"WaveNet trial 1\")\n",
    "plt.xlabel(\"1000*x training step\")\n",
    "plt.ylabel(\"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wavenet trial 1：效果不佳\n",
    "#下一步实验：清洗出正好符合结构的sequence=8的数据进行试验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wavenet trial 2：\n",
    "#导入train数据\n",
    "a=np.load(\"wave_train_data.npy\")\n",
    "b=a.reshape([a.shape[0],a.shape[1]*a.shape[2]])\n",
    "c=b[~np.isnan(b).any(axis=1),:]\n",
    "train_data=c.reshape([c.shape[0], a.shape[1],a.shape[2]])\n",
    "d=np.load(\"wave_train_label.npy\").reshape(-1,1)\n",
    "train_label=d[~np.isnan(b).any(axis=1),:].reshape(-1,)\n",
    "#导入valid数据\n",
    "a=np.load(\"wave_valid_data.npy\")\n",
    "b=a.reshape([a.shape[0],a.shape[1]*a.shape[2]])\n",
    "c=b[~np.isnan(b).any(axis=1),:]\n",
    "valid_data=c.reshape([c.shape[0], a.shape[1],a.shape[2]])\n",
    "d=np.load(\"wave_valid_label.npy\").reshape(-1,1)\n",
    "valid_label=d[~np.isnan(b).any(axis=1),:].reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.transpose(train_data,(0,2,1))\n",
    "valid_data = np.transpose(valid_data,(0,2,1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49745, 42, 8), (21317, 42, 8))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, valid_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2 \n",
    "in_depth=128 \n",
    "in_channels=42 \n",
    "skip_channels=64 \n",
    "dilation_depth=3 \n",
    "device= torch.device(\"cuda:1\")\n",
    "batch_size=128\n",
    "learning_rate=0.001\n",
    "num_epochs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=GetLoader(train_data,train_label)\n",
    "valid=GetLoader(valid_data,valid_label)\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train,batch_size=batch_size,shuffle=True,num_workers=0)\n",
    "valid_loader=torch.utils.data.DataLoader(dataset=valid,batch_size=valid_data.shape[0],shuffle=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WaveNet(\n",
       "  (conv1): Conv1d(42, 32, kernel_size=(2,), stride=(1,), padding=(1,), bias=False)\n",
       "  (main): ModuleList(\n",
       "    (0): ResidualBlock(\n",
       "      (filter_conv): DilatedConv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "      (gate_conv): DilatedConv1d(32, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
       "      (skip_conv): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "      (residual_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (filter_conv): DilatedConv1d(32, 32, kernel_size=(2,), stride=(1,), dilation=(2,), bias=False)\n",
       "      (gate_conv): DilatedConv1d(32, 32, kernel_size=(2,), stride=(1,), dilation=(2,), bias=False)\n",
       "      (skip_conv): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "      (residual_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (filter_conv): DilatedConv1d(32, 32, kernel_size=(2,), stride=(1,), dilation=(4,), bias=False)\n",
       "      (gate_conv): DilatedConv1d(32, 32, kernel_size=(2,), stride=(1,), dilation=(4,), bias=False)\n",
       "      (skip_conv): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "      (residual_conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (post): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "    (2): ReLU()\n",
       "    (3): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavenet = WaveNet(num_classes, in_depth, in_channels, skip_channels, dilation_depth, device)\n",
    "wavenet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(wavenet.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step=0\n",
    "train_precision=[]\n",
    "valid_precision=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/1000],step[1000] Loss:0.6792\n",
      "precision of the model on thetrainingdata: 40.0%\n",
      "precision of the model on thevalidationdata: 55.72289276123047%\n",
      "Epoch [6/1000],step[2000] Loss:0.6774\n",
      "precision of the model on thetrainingdata: 55.319149017333984%\n",
      "precision of the model on thevalidationdata: 52.509124755859375%\n",
      "Epoch [8/1000],step[3000] Loss:0.6684\n",
      "precision of the model on thetrainingdata: 68.18181610107422%\n",
      "precision of the model on thevalidationdata: 54.66666793823242%\n",
      "Epoch [11/1000],step[4000] Loss:0.6799\n",
      "precision of the model on thetrainingdata: 54.761905670166016%\n",
      "precision of the model on thevalidationdata: 56.9331169128418%\n",
      "Epoch [13/1000],step[5000] Loss:0.6779\n",
      "precision of the model on thetrainingdata: 64.81481170654297%\n",
      "precision of the model on thevalidationdata: 57.079647064208984%\n",
      "Epoch [16/1000],step[6000] Loss:0.6604\n",
      "precision of the model on thetrainingdata: 44.44444274902344%\n",
      "precision of the model on thevalidationdata: 55.241458892822266%\n",
      "Epoch [18/1000],step[7000] Loss:0.6813\n",
      "precision of the model on thetrainingdata: 59.25925827026367%\n",
      "precision of the model on thevalidationdata: 60.18922805786133%\n",
      "Epoch [21/1000],step[8000] Loss:0.6337\n",
      "precision of the model on thetrainingdata: 69.64286041259766%\n",
      "precision of the model on thevalidationdata: 52.10389709472656%\n",
      "Epoch [24/1000],step[9000] Loss:0.6943\n",
      "precision of the model on thetrainingdata: 68.0%\n",
      "precision of the model on thevalidationdata: 52.15869140625%\n",
      "Epoch [26/1000],step[10000] Loss:0.6615\n",
      "precision of the model on thetrainingdata: 65.51724243164062%\n",
      "precision of the model on thevalidationdata: 54.652687072753906%\n",
      "Epoch [29/1000],step[11000] Loss:0.5946\n",
      "precision of the model on thetrainingdata: 67.64705657958984%\n",
      "precision of the model on thevalidationdata: 53.8320198059082%\n",
      "Epoch [31/1000],step[12000] Loss:0.6867\n",
      "precision of the model on thetrainingdata: 56.410255432128906%\n",
      "precision of the model on thevalidationdata: 55.67911148071289%\n",
      "Epoch [34/1000],step[13000] Loss:0.6757\n",
      "precision of the model on thetrainingdata: 63.6363639831543%\n",
      "precision of the model on thevalidationdata: 56.2182731628418%\n",
      "Epoch [36/1000],step[14000] Loss:0.6395\n",
      "precision of the model on thetrainingdata: 55.8139533996582%\n",
      "precision of the model on thevalidationdata: 55.16453552246094%\n",
      "Epoch [39/1000],step[15000] Loss:0.6308\n",
      "precision of the model on thetrainingdata: 54.28571319580078%\n",
      "precision of the model on thevalidationdata: 56.987491607666016%\n",
      "Epoch [42/1000],step[16000] Loss:0.5705\n",
      "precision of the model on thetrainingdata: 75.55555725097656%\n",
      "precision of the model on thevalidationdata: 55.1971321105957%\n",
      "Epoch [44/1000],step[17000] Loss:0.6172\n",
      "precision of the model on thetrainingdata: 65.71428680419922%\n",
      "precision of the model on thevalidationdata: 55.96140670776367%\n",
      "Epoch [47/1000],step[18000] Loss:0.6043\n",
      "precision of the model on thetrainingdata: 62.22222137451172%\n",
      "precision of the model on thevalidationdata: 55.09072494506836%\n",
      "Epoch [49/1000],step[19000] Loss:0.5828\n",
      "precision of the model on thetrainingdata: 84.61538696289062%\n",
      "precision of the model on thevalidationdata: 56.72215270996094%\n",
      "Epoch [52/1000],step[20000] Loss:0.6054\n",
      "precision of the model on thetrainingdata: 71.79486846923828%\n",
      "precision of the model on thevalidationdata: 54.64700698852539%\n",
      "Epoch [54/1000],step[21000] Loss:0.6549\n",
      "precision of the model on thetrainingdata: 67.74193572998047%\n",
      "precision of the model on thevalidationdata: 56.06590270996094%\n",
      "Epoch [57/1000],step[22000] Loss:0.5966\n",
      "precision of the model on thetrainingdata: 81.25%\n",
      "precision of the model on thevalidationdata: 53.63550567626953%\n",
      "Epoch [60/1000],step[23000] Loss:0.5276\n",
      "precision of the model on thetrainingdata: 66.66666412353516%\n",
      "precision of the model on thevalidationdata: 56.50764083862305%\n",
      "Epoch [62/1000],step[24000] Loss:0.5734\n",
      "precision of the model on thetrainingdata: 60.0%\n",
      "precision of the model on thevalidationdata: 56.54450225830078%\n",
      "Epoch [65/1000],step[25000] Loss:0.6499\n",
      "precision of the model on thetrainingdata: 72.4137954711914%\n",
      "precision of the model on thevalidationdata: 54.930171966552734%\n",
      "Epoch [67/1000],step[26000] Loss:0.5456\n",
      "precision of the model on thetrainingdata: 62.16216278076172%\n",
      "precision of the model on thevalidationdata: 55.496612548828125%\n",
      "Epoch [70/1000],step[27000] Loss:0.5769\n",
      "precision of the model on thetrainingdata: 68.18181610107422%\n",
      "precision of the model on thevalidationdata: 54.523521423339844%\n",
      "Epoch [72/1000],step[28000] Loss:0.6049\n",
      "precision of the model on thetrainingdata: 70.45454406738281%\n",
      "precision of the model on thevalidationdata: 53.518680572509766%\n",
      "Epoch [75/1000],step[29000] Loss:0.5703\n",
      "precision of the model on thetrainingdata: 70.0%\n",
      "precision of the model on thevalidationdata: 56.21865463256836%\n",
      "Epoch [78/1000],step[30000] Loss:0.5618\n",
      "precision of the model on thetrainingdata: 68.75%\n",
      "precision of the model on thevalidationdata: 54.80226135253906%\n",
      "Epoch [80/1000],step[31000] Loss:0.5648\n",
      "precision of the model on thetrainingdata: 69.69696807861328%\n",
      "precision of the model on thevalidationdata: 51.561248779296875%\n",
      "Epoch [83/1000],step[32000] Loss:0.5860\n",
      "precision of the model on thetrainingdata: 78.37837982177734%\n",
      "precision of the model on thevalidationdata: 54.79945755004883%\n",
      "Epoch [85/1000],step[33000] Loss:0.5777\n",
      "precision of the model on thetrainingdata: 80.6451644897461%\n",
      "precision of the model on thevalidationdata: 53.549278259277344%\n",
      "Epoch [88/1000],step[34000] Loss:0.5911\n",
      "precision of the model on thetrainingdata: 68.29268646240234%\n",
      "precision of the model on thevalidationdata: 57.79220962524414%\n",
      "Epoch [90/1000],step[35000] Loss:0.6222\n",
      "precision of the model on thetrainingdata: 78.78787994384766%\n",
      "precision of the model on thevalidationdata: 53.56501007080078%\n",
      "Epoch [93/1000],step[36000] Loss:0.5450\n",
      "precision of the model on thetrainingdata: 76.08695983886719%\n",
      "precision of the model on thevalidationdata: 56.61668014526367%\n",
      "Epoch [96/1000],step[37000] Loss:0.5441\n",
      "precision of the model on thetrainingdata: 73.33333587646484%\n",
      "precision of the model on thevalidationdata: 54.39560317993164%\n",
      "Epoch [98/1000],step[38000] Loss:0.5877\n",
      "precision of the model on thetrainingdata: 75.67567443847656%\n",
      "precision of the model on thevalidationdata: 51.52370071411133%\n",
      "Epoch [101/1000],step[39000] Loss:0.5935\n",
      "precision of the model on thetrainingdata: 69.81131744384766%\n",
      "precision of the model on thevalidationdata: 53.010658264160156%\n",
      "Epoch [103/1000],step[40000] Loss:0.5597\n",
      "precision of the model on thetrainingdata: 71.42857360839844%\n",
      "precision of the model on thevalidationdata: 54.53699493408203%\n",
      "Epoch [106/1000],step[41000] Loss:0.5653\n",
      "precision of the model on thetrainingdata: 76.92308044433594%\n",
      "precision of the model on thevalidationdata: 53.1397705078125%\n",
      "Epoch [108/1000],step[42000] Loss:0.6116\n",
      "precision of the model on thetrainingdata: 62.5%\n",
      "precision of the model on thevalidationdata: 55.36147689819336%\n",
      "Epoch [111/1000],step[43000] Loss:0.5496\n",
      "precision of the model on thetrainingdata: 80.76923370361328%\n",
      "precision of the model on thevalidationdata: 56.20532989501953%\n",
      "Epoch [114/1000],step[44000] Loss:0.5758\n",
      "precision of the model on thetrainingdata: 64.58333587646484%\n",
      "precision of the model on thevalidationdata: 55.76786804199219%\n",
      "Epoch [116/1000],step[45000] Loss:0.5639\n",
      "precision of the model on thetrainingdata: 70.0%\n",
      "precision of the model on thevalidationdata: 57.849605560302734%\n",
      "Epoch [119/1000],step[46000] Loss:0.5349\n",
      "precision of the model on thetrainingdata: 70.27027130126953%\n",
      "precision of the model on thevalidationdata: 55.06379699707031%\n",
      "Epoch [121/1000],step[47000] Loss:0.5826\n",
      "precision of the model on thetrainingdata: 79.06977081298828%\n",
      "precision of the model on thevalidationdata: 53.37483596801758%\n",
      "Epoch [124/1000],step[48000] Loss:0.6078\n",
      "precision of the model on thetrainingdata: 72.34042358398438%\n",
      "precision of the model on thevalidationdata: 55.1436767578125%\n",
      "Epoch [126/1000],step[49000] Loss:0.5384\n",
      "precision of the model on thetrainingdata: 70.0%\n",
      "precision of the model on thevalidationdata: 54.94316101074219%\n",
      "Epoch [129/1000],step[50000] Loss:0.5090\n",
      "precision of the model on thetrainingdata: 72.5%\n",
      "precision of the model on thevalidationdata: 55.217716217041016%\n",
      "Epoch [132/1000],step[51000] Loss:0.5776\n",
      "precision of the model on thetrainingdata: 75.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision of the model on thevalidationdata: 55.0%\n",
      "Epoch [134/1000],step[52000] Loss:0.5701\n",
      "precision of the model on thetrainingdata: 73.91304016113281%\n",
      "precision of the model on thevalidationdata: 55.524078369140625%\n",
      "Epoch [137/1000],step[53000] Loss:0.5927\n",
      "precision of the model on thetrainingdata: 85.71428680419922%\n",
      "precision of the model on thevalidationdata: 56.10200500488281%\n",
      "Epoch [139/1000],step[54000] Loss:0.5008\n",
      "precision of the model on thetrainingdata: 69.76744079589844%\n",
      "precision of the model on thevalidationdata: 55.42671585083008%\n",
      "Epoch [142/1000],step[55000] Loss:0.5732\n",
      "precision of the model on thetrainingdata: 76.08695983886719%\n",
      "precision of the model on thevalidationdata: 55.31219482421875%\n",
      "Epoch [144/1000],step[56000] Loss:0.5361\n",
      "precision of the model on thetrainingdata: 75.0%\n",
      "precision of the model on thevalidationdata: 54.73684310913086%\n",
      "Epoch [147/1000],step[57000] Loss:0.5180\n",
      "precision of the model on thetrainingdata: 82.05128479003906%\n",
      "precision of the model on thevalidationdata: 53.813140869140625%\n",
      "Epoch [150/1000],step[58000] Loss:0.5053\n",
      "precision of the model on thetrainingdata: 68.18181610107422%\n",
      "precision of the model on thevalidationdata: 54.664119720458984%\n",
      "Epoch [152/1000],step[59000] Loss:0.5439\n",
      "precision of the model on thetrainingdata: 79.4871826171875%\n",
      "precision of the model on thevalidationdata: 57.995880126953125%\n",
      "Epoch [155/1000],step[60000] Loss:0.6323\n",
      "precision of the model on thetrainingdata: 80.0%\n",
      "precision of the model on thevalidationdata: 55.622642517089844%\n",
      "Epoch [157/1000],step[61000] Loss:0.5461\n",
      "precision of the model on thetrainingdata: 73.91304016113281%\n",
      "precision of the model on thevalidationdata: 54.29544448852539%\n",
      "Epoch [160/1000],step[62000] Loss:0.5313\n",
      "precision of the model on thetrainingdata: 76.47058868408203%\n",
      "precision of the model on thevalidationdata: 55.11575698852539%\n",
      "Epoch [162/1000],step[63000] Loss:0.5087\n",
      "precision of the model on thetrainingdata: 87.8787841796875%\n",
      "precision of the model on thevalidationdata: 55.86708068847656%\n",
      "Epoch [165/1000],step[64000] Loss:0.6377\n",
      "precision of the model on thetrainingdata: 77.14286041259766%\n",
      "precision of the model on thevalidationdata: 59.510704040527344%\n",
      "Epoch [168/1000],step[65000] Loss:0.5578\n",
      "precision of the model on thetrainingdata: 78.57142639160156%\n",
      "precision of the model on thevalidationdata: 54.03520584106445%\n",
      "Epoch [170/1000],step[66000] Loss:0.4407\n",
      "precision of the model on thetrainingdata: 78.72340393066406%\n",
      "precision of the model on thevalidationdata: 53.42417907714844%\n",
      "Epoch [173/1000],step[67000] Loss:0.5688\n",
      "precision of the model on thetrainingdata: 83.33333587646484%\n",
      "precision of the model on thevalidationdata: 56.95266342163086%\n",
      "Epoch [175/1000],step[68000] Loss:0.5282\n",
      "precision of the model on thetrainingdata: 68.75%\n",
      "precision of the model on thevalidationdata: 55.16921615600586%\n",
      "Epoch [178/1000],step[69000] Loss:0.5462\n",
      "precision of the model on thetrainingdata: 80.95237731933594%\n",
      "precision of the model on thevalidationdata: 55.12161636352539%\n",
      "Epoch [180/1000],step[70000] Loss:0.5475\n",
      "precision of the model on thetrainingdata: 74.19355010986328%\n",
      "precision of the model on thevalidationdata: 53.06122589111328%\n",
      "Epoch [183/1000],step[71000] Loss:0.5896\n",
      "precision of the model on thetrainingdata: 71.42857360839844%\n",
      "precision of the model on thevalidationdata: 53.967445373535156%\n",
      "Epoch [186/1000],step[72000] Loss:0.5480\n",
      "precision of the model on thetrainingdata: 73.52941131591797%\n",
      "precision of the model on thevalidationdata: 57.57575607299805%\n",
      "Epoch [188/1000],step[73000] Loss:0.5133\n",
      "precision of the model on thetrainingdata: 70.0%\n",
      "precision of the model on thevalidationdata: 53.737491607666016%\n",
      "Epoch [191/1000],step[74000] Loss:0.5080\n",
      "precision of the model on thetrainingdata: 82.92682647705078%\n",
      "precision of the model on thevalidationdata: 56.41339874267578%\n",
      "Epoch [193/1000],step[75000] Loss:0.5340\n",
      "precision of the model on thetrainingdata: 77.5%\n",
      "precision of the model on thevalidationdata: 58.5323486328125%\n",
      "Epoch [196/1000],step[76000] Loss:0.4994\n",
      "precision of the model on thetrainingdata: 81.81818389892578%\n",
      "precision of the model on thevalidationdata: 52.339603424072266%\n",
      "Epoch [198/1000],step[77000] Loss:0.5203\n",
      "precision of the model on thetrainingdata: 70.0%\n",
      "precision of the model on thevalidationdata: 55.75492477416992%\n",
      "Epoch [201/1000],step[78000] Loss:0.5437\n",
      "precision of the model on thetrainingdata: 80.0%\n",
      "precision of the model on thevalidationdata: 55.167842864990234%\n",
      "Epoch [204/1000],step[79000] Loss:0.5000\n",
      "precision of the model on thetrainingdata: 90.47618865966797%\n",
      "precision of the model on thevalidationdata: 54.046119689941406%\n",
      "Epoch [206/1000],step[80000] Loss:0.4831\n",
      "precision of the model on thetrainingdata: 63.6363639831543%\n",
      "precision of the model on thevalidationdata: 53.462284088134766%\n",
      "Epoch [209/1000],step[81000] Loss:0.4468\n",
      "precision of the model on thetrainingdata: 83.33333587646484%\n",
      "precision of the model on thevalidationdata: 51.79611587524414%\n",
      "Epoch [211/1000],step[82000] Loss:0.5327\n",
      "precision of the model on thetrainingdata: 62.5%\n",
      "precision of the model on thevalidationdata: 54.76451110839844%\n",
      "Epoch [214/1000],step[83000] Loss:0.5073\n",
      "precision of the model on thetrainingdata: 81.25%\n",
      "precision of the model on thevalidationdata: 55.03662872314453%\n",
      "Epoch [216/1000],step[84000] Loss:0.5703\n",
      "precision of the model on thetrainingdata: 62.85714340209961%\n",
      "precision of the model on thevalidationdata: 53.50230407714844%\n",
      "Epoch [219/1000],step[85000] Loss:0.5405\n",
      "precision of the model on thetrainingdata: 66.66666412353516%\n",
      "precision of the model on thevalidationdata: 54.29941940307617%\n",
      "Epoch [222/1000],step[86000] Loss:0.5147\n",
      "precision of the model on thetrainingdata: 74.19355010986328%\n",
      "precision of the model on thevalidationdata: 54.08213806152344%\n",
      "Epoch [224/1000],step[87000] Loss:0.5015\n",
      "precision of the model on thetrainingdata: 82.5%\n",
      "precision of the model on thevalidationdata: 57.883522033691406%\n",
      "Epoch [227/1000],step[88000] Loss:0.5123\n",
      "precision of the model on thetrainingdata: 80.48780822753906%\n",
      "precision of the model on thevalidationdata: 56.4991340637207%\n",
      "Epoch [229/1000],step[89000] Loss:0.5629\n",
      "precision of the model on thetrainingdata: 66.0%\n",
      "precision of the model on thevalidationdata: 54.260528564453125%\n",
      "Epoch [232/1000],step[90000] Loss:0.6160\n",
      "precision of the model on thetrainingdata: 68.57142639160156%\n",
      "precision of the model on thevalidationdata: 54.61300277709961%\n"
     ]
    }
   ],
   "source": [
    "#训练过程\n",
    "for epoch in range(num_epochs):\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images=images.type(torch.FloatTensor)\n",
    "        labels=labels.type(torch.FloatTensor)\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        #forward pass\n",
    "        outputs=wavenet(images)\n",
    "        loss=loss_function(outputs,labels.long())\n",
    "        \n",
    "        #Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_step+=1\n",
    "        if total_step>90*1000:\n",
    "            break\n",
    "        if (total_step)%1000==0:#each 10 iterations is one epoch\n",
    "            print(\"Epoch [{}/{}],step[{}] Loss:{:.4f}\".format(epoch+1,num_epochs,total_step,loss.item()))\n",
    "            _,train_pre=predict_precision(wavenet,images,labels,device,predict_type='training')\n",
    "            train_precision.append(train_pre)\n",
    "            for images, labels in valid_loader:\n",
    "                _,valid_pre=predict_precision(wavenet,images,labels,device,predict_type='validation')\n",
    "            valid_precision.append(valid_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_precision,label=\"training precision\")\n",
    "plt.plot(valid_precision,label=\"validation precision\")\n",
    "plt.title(\"WaveNet trial 2\")\n",
    "plt.xlabel(\"1000*x training step\")\n",
    "plt.ylabel(\"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wavenet trial 2:表现稳定在precision 0.55-0.58，但还有gradient vanishing问题没有解决\n",
    "#下一步试验：调整参数解决gradient vanishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wavenet trial 3：\n",
    "num_classes=2 \n",
    "in_depth=64 \n",
    "in_channels=42 \n",
    "skip_channels=64 \n",
    "dilation_depth=3 \n",
    "device= torch.device(\"cuda:1\")\n",
    "batch_size=128\n",
    "learning_rate=0.0001\n",
    "num_epochs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=GetLoader(train_data,train_label)\n",
    "valid=GetLoader(valid_data,valid_label)\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train,batch_size=batch_size,shuffle=True,num_workers=0)\n",
    "valid_loader=torch.utils.data.DataLoader(dataset=valid,batch_size=valid_data.shape[0],shuffle=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wavenet = WaveNet(num_classes, in_depth, in_channels, skip_channels, dilation_depth, device)\n",
    "wavenet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(wavenet.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step=0\n",
    "train_precision=[]\n",
    "valid_precision=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#训练过程\n",
    "for epoch in range(num_epochs):\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images=images.type(torch.FloatTensor)\n",
    "        labels=labels.type(torch.FloatTensor)\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        #forward pass\n",
    "        outputs=wavenet(images)\n",
    "        loss=loss_function(outputs,labels.long())\n",
    "        \n",
    "        #Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_step+=1\n",
    "        if (total_step)%1000==0:#each 10 iterations is one epoch\n",
    "            print(\"Epoch [{}/{}],step[{}] Loss:{:.4f}\".format(epoch+1,num_epochs,total_step,loss.item()))\n",
    "            _,train_pre=predict_precision(wavenet,images,labels,device,predict_type='training')\n",
    "            train_precision.append(train_pre)\n",
    "            for images, labels in valid_loader:\n",
    "                _,valid_pre=predict_precision(wavenet,images,labels,device,predict_type='validation')\n",
    "            valid_precision.append(valid_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_precision,label=\"training precision\")\n",
    "plt.plot(valid_precision,label=\"validation precision\")\n",
    "plt.title(\"WaveNet trial 3\")\n",
    "plt.xlabel(\"1000*x training step\")\n",
    "plt.ylabel(\"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wavenet trial 3:将最终的conv channel数减少，有一定的效果\n",
    "#下一步试验：增加bacth_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, res_channels, skip_channels, dilation):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.filter_conv = DilatedConv1d(in_channels=res_channels, out_channels=res_channels, dilation=dilation)\n",
    "        self.gate_conv = DilatedConv1d(in_channels=res_channels, out_channels=res_channels, dilation=dilation)\n",
    "        self.skip_conv = nn.Conv1d(in_channels=res_channels, out_channels=skip_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(res_channels)\n",
    "        self.residual_conv = nn.Conv1d(in_channels=res_channels, out_channels=res_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        #print(dilation)\n",
    "        inputs = self.bn1(inputs)\n",
    "        sigmoid_out = torch.sigmoid(self.gate_conv(inputs))\n",
    "        tahn_out = torch.tanh(self.filter_conv(inputs))\n",
    "        output = sigmoid_out * tahn_out\n",
    "        #\n",
    "        skip_out = self.skip_conv(output)\n",
    "        res_out = self.residual_conv(output)\n",
    "        res_out = res_out + inputs[:, :, -res_out.size(2):]\n",
    "        # res\n",
    "        return res_out , skip_out\n",
    "    \n",
    "\n",
    "\n",
    "class WaveNet(nn.Module):\n",
    "    def __init__(self, num_classes, in_depth=128, in_channels=42, skip_channels=64, dilation_depth=7, device=torch.device(\"cpu\")):\n",
    "        super(WaveNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=32,\n",
    "                               kernel_size=2, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        self.dilations = [2**i for i in range(dilation_depth)]\n",
    "        self.main = nn.ModuleList([ResidualBlock(res_channels=32, \n",
    "                                                 skip_channels=skip_channels,dilation=dilation) for dilation in self.dilations])\n",
    "        #self.pre = nn.Embedding(in_depth, res_channels)\n",
    "        #self.pre_conv = CausalConv1d(in_channels=res_channels, out_channels=res_channels)\n",
    "        self.post = nn.Sequential(nn.BatchNorm1d(skip_channels),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Conv1d(skip_channels,skip_channels,1),\n",
    "                                  nn.BatchNorm1d(skip_channels),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Conv1d(skip_channels,in_depth,kernel_size=1))\n",
    "        self.fc = nn.Linear(in_depth*2, num_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight.to(device), mode='fan_out', nonlinearity='relu')\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        #outputs = self.preprocess(inputs)\n",
    "        skip_connections = []\n",
    "        \n",
    "        outputs = self.conv1(inputs)\n",
    "        \n",
    "        for layer in self.main:\n",
    "            outputs,skip = layer(outputs)\n",
    "            skip_connections.append(skip)\n",
    "        #print(outputs.shape)\n",
    "        outputs = sum([s[:,:,-outputs.size(2):] for s in skip_connections])\n",
    "        #print(\"shape\")\n",
    "        outputs = self.post(outputs)\n",
    "        #print(outputs.shape)  \n",
    "        outputs = torch.flatten(outputs, 1)\n",
    "        #print(outputs.shape)\n",
    "        outputs = self.fc(outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wavenet = WaveNet(num_classes, in_depth, in_channels, skip_channels, dilation_depth, device)\n",
    "wavenet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(wavenet.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step=0\n",
    "train_precision=[]\n",
    "valid_precision=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#训练过程\n",
    "for epoch in range(num_epochs):\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images=images.type(torch.FloatTensor)\n",
    "        labels=labels.type(torch.FloatTensor)\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        #forward pass\n",
    "        outputs=wavenet(images)\n",
    "        loss=loss_function(outputs,labels.long())\n",
    "        \n",
    "        #Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_step+=1\n",
    "        if (total_step)%1000==0:#each 10 iterations is one epoch\n",
    "            print(\"Epoch [{}/{}],step[{}] Loss:{:.4f}\".format(epoch+1,num_epochs,total_step,loss.item()))\n",
    "            _,train_pre=predict_precision(wavenet,images,labels,device,predict_type='training')\n",
    "            train_precision.append(train_pre)\n",
    "            for images, labels in valid_loader:\n",
    "                _,valid_pre=predict_precision(wavenet,images,labels,device,predict_type='validation')\n",
    "            valid_precision.append(valid_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_precision,label=\"training precision\")\n",
    "plt.plot(valid_precision,label=\"validation precision\")\n",
    "plt.title(\"WaveNet trial 4\")\n",
    "plt.xlabel(\"1000*x training step\")\n",
    "plt.ylabel(\"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#结论：batch_norm不管用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision of the model on thevalidationdata: 55.79344940185547%\n"
     ]
    }
   ],
   "source": [
    "for images, labels in valid_loader:\n",
    "    with torch.no_grad():\n",
    "        correct=0\n",
    "        total=0\n",
    "        images=images.type(torch.FloatTensor)\n",
    "        labels=labels.type(torch.FloatTensor)\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs=wavenet(images)\n",
    "        _,predicted=torch.max(outputs.data,1)\n",
    "        softmax=nn.Softmax(-1)\n",
    "        outputs=softmax(outputs)\n",
    "        total+=sum(predicted)\n",
    "        correct+=(sum(predicted*labels))\n",
    "        print('precision of the model on the'+'validation'+'data: {}%'.format(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.5932, 0.5932, 0.5383,  ..., 0.5721, 0.5505, 0.5702], device='cuda:1'),\n",
       "indices=tensor([0, 0, 1,  ..., 0, 0, 0], device='cuda:1'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(outputs,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5465, 0.4535],\n",
       "        [0.5465, 0.4535],\n",
       "        [0.4808, 0.5192],\n",
       "        ...,\n",
       "        [0.5360, 0.4640],\n",
       "        [0.5252, 0.4748],\n",
       "        [0.5350, 0.4650]], device='cuda:1')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=nn.Softmax(-1)\n",
    "s(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
