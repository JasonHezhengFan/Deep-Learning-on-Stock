{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "import classification_models\n",
    "from classification_models import GetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入训练数据\n",
    "a=np.load(\"new_train_data.npy\")\n",
    "b=a.reshape([a.shape[0],a.shape[1]*a.shape[2]])\n",
    "c=b[~np.isnan(b).any(axis=1),:]\n",
    "train_data=c.reshape([c.shape[0], a.shape[1],a.shape[2]])\n",
    "d=np.load(\"new_train_label.npy\").reshape(-1,1)\n",
    "train_label=d[~np.isnan(b).any(axis=1),:].reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入valid数据\n",
    "a=np.load(\"new_valid_data.npy\")\n",
    "b=a.reshape([a.shape[0],a.shape[1]*a.shape[2]])\n",
    "c=b[~np.isnan(b).any(axis=1),:]\n",
    "valid_data=c.reshape([c.shape[0], a.shape[1],a.shape[2]])\n",
    "d=np.load(\"new_valid_label.npy\").reshape(-1,1)\n",
    "valid_label=d[~np.isnan(b).any(axis=1),:].reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((397353, 10, 42), (397353,), (48055, 10, 42), (48055,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape,train_label.shape,valid_data.shape,valid_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_precision(model,images,labels,device,predict_type):\n",
    "    with torch.no_grad():\n",
    "        correct=0\n",
    "        total=0\n",
    "        images=images.type(torch.FloatTensor)\n",
    "        labels=labels.type(torch.FloatTensor)\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs=model(images)\n",
    "        _,predicted=torch.max(outputs.data,1)\n",
    "        total+=sum(predicted)\n",
    "        correct+=(sum(predicted*labels))\n",
    "        print('precision of the model on the'+predict_type+'data: {}%'.format(100*correct/total))\n",
    "    return predicted, 100*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRIAL1\n",
    "from classification_models import LSTM\n",
    "# Hyper Parameters\n",
    "sequence_length = 10  # 序列长度，将图像的每一列作为一个序列\n",
    "input_size = 42  # 输入数据的维度\n",
    "hidden_size = 128  # 隐藏层的size\n",
    "num_layers =  4 # 有多少层\n",
    "\n",
    "num_classes = 2\n",
    "batch_size = 1024\n",
    "num_epochs = 800\n",
    "learning_rate = 0.001\n",
    "\n",
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(42, 128, num_layers=4, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes,device=device)\n",
    "lstm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=GetLoader(train_data,train_label)\n",
    "valid=GetLoader(valid_data,valid_label)\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train,batch_size=batch_size,shuffle=True,num_workers=8)\n",
    "valid_loader=torch.utils.data.DataLoader(dataset=valid,batch_size=valid_data.shape[0],shuffle=False,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step=0\n",
    "train_precision=[]\n",
    "valid_precision=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/800],step[2000] Loss:0.6810\n",
      "precision of the model on thetrainingdata: 58.00865936279297%\n",
      "precision of the model on thevalidationdata: 49.09107208251953%\n",
      "Epoch [6/800],step[3000] Loss:0.6682\n",
      "precision of the model on thetrainingdata: 64.70587921142578%\n",
      "precision of the model on thevalidationdata: 49.0029411315918%\n",
      "Epoch [8/800],step[4000] Loss:0.6618\n",
      "precision of the model on thetrainingdata: 60.7843132019043%\n",
      "precision of the model on thevalidationdata: 49.33353042602539%\n",
      "Epoch [11/800],step[5000] Loss:0.6623\n",
      "precision of the model on thetrainingdata: 62.910797119140625%\n",
      "precision of the model on thevalidationdata: 49.13975143432617%\n",
      "Epoch [13/800],step[6000] Loss:0.6621\n",
      "precision of the model on thetrainingdata: 61.47186279296875%\n",
      "precision of the model on thevalidationdata: 48.804813385009766%\n",
      "Epoch [16/800],step[7000] Loss:0.6442\n",
      "precision of the model on thetrainingdata: 66.92607116699219%\n",
      "precision of the model on thevalidationdata: 47.887638092041016%\n",
      "Epoch [18/800],step[8000] Loss:0.6266\n",
      "precision of the model on thetrainingdata: 70.8154525756836%\n",
      "precision of the model on thevalidationdata: 48.016536712646484%\n",
      "Epoch [21/800],step[9000] Loss:0.5946\n",
      "precision of the model on thetrainingdata: 70.97901916503906%\n",
      "precision of the model on thevalidationdata: 47.72268295288086%\n",
      "Epoch [24/800],step[10000] Loss:0.5948\n",
      "precision of the model on thetrainingdata: 68.0412368774414%\n",
      "precision of the model on thevalidationdata: 47.88814926147461%\n",
      "Epoch [26/800],step[11000] Loss:0.5656\n",
      "precision of the model on thetrainingdata: 71.92982482910156%\n",
      "precision of the model on thevalidationdata: 48.295616149902344%\n",
      "Epoch [29/800],step[12000] Loss:0.5839\n",
      "precision of the model on thetrainingdata: 65.51724243164062%\n",
      "precision of the model on thevalidationdata: 47.767799377441406%\n",
      "Epoch [31/800],step[13000] Loss:0.5509\n",
      "precision of the model on thetrainingdata: 69.90595245361328%\n",
      "precision of the model on thevalidationdata: 47.873046875%\n",
      "Epoch [34/800],step[14000] Loss:0.5542\n",
      "precision of the model on thetrainingdata: 68.45426177978516%\n",
      "precision of the model on thevalidationdata: 48.250125885009766%\n",
      "Epoch [36/800],step[15000] Loss:0.5555\n",
      "precision of the model on thetrainingdata: 72.36363983154297%\n",
      "precision of the model on thevalidationdata: 47.56619644165039%\n",
      "Epoch [39/800],step[16000] Loss:0.5256\n",
      "precision of the model on thetrainingdata: 71.24182891845703%\n",
      "precision of the model on thevalidationdata: 47.97822189331055%\n",
      "Epoch [42/800],step[17000] Loss:0.5395\n",
      "precision of the model on thetrainingdata: 71.20252990722656%\n",
      "precision of the model on thevalidationdata: 47.914451599121094%\n",
      "Epoch [44/800],step[18000] Loss:0.5084\n",
      "precision of the model on thetrainingdata: 77.04402160644531%\n",
      "precision of the model on thevalidationdata: 48.061466217041016%\n",
      "Epoch [47/800],step[19000] Loss:0.4766\n",
      "precision of the model on thetrainingdata: 78.9173812866211%\n",
      "precision of the model on thevalidationdata: 47.3831672668457%\n",
      "Epoch [49/800],step[20000] Loss:0.5004\n",
      "precision of the model on thetrainingdata: 72.9344711303711%\n",
      "precision of the model on thevalidationdata: 47.95547866821289%\n",
      "Epoch [52/800],step[21000] Loss:0.4689\n",
      "precision of the model on thetrainingdata: 78.64865112304688%\n",
      "precision of the model on thevalidationdata: 47.63599395751953%\n",
      "Epoch [54/800],step[22000] Loss:0.4848\n",
      "precision of the model on thetrainingdata: 79.03225708007812%\n",
      "precision of the model on thevalidationdata: 47.6998176574707%\n",
      "Epoch [57/800],step[23000] Loss:0.4560\n",
      "precision of the model on thetrainingdata: 82.59668731689453%\n",
      "precision of the model on thevalidationdata: 47.534141540527344%\n",
      "Epoch [60/800],step[24000] Loss:0.4245\n",
      "precision of the model on thetrainingdata: 82.82548522949219%\n",
      "precision of the model on thevalidationdata: 47.660030364990234%\n",
      "Epoch [62/800],step[25000] Loss:0.4744\n",
      "precision of the model on thetrainingdata: 78.82037353515625%\n",
      "precision of the model on thevalidationdata: 47.91678237915039%\n",
      "Epoch [65/800],step[26000] Loss:0.4507\n",
      "precision of the model on thetrainingdata: 82.96703338623047%\n",
      "precision of the model on thevalidationdata: 47.90676498413086%\n",
      "Epoch [67/800],step[27000] Loss:0.4350\n",
      "precision of the model on thetrainingdata: 78.93174743652344%\n",
      "precision of the model on thevalidationdata: 47.96528625488281%\n",
      "Epoch [70/800],step[28000] Loss:0.4061\n",
      "precision of the model on thetrainingdata: 80.10752868652344%\n",
      "precision of the model on thevalidationdata: 47.91960525512695%\n",
      "Epoch [72/800],step[29000] Loss:0.3942\n",
      "precision of the model on thetrainingdata: 87.10691833496094%\n",
      "precision of the model on thevalidationdata: 47.788944244384766%\n",
      "Epoch [75/800],step[30000] Loss:0.4173\n",
      "precision of the model on thetrainingdata: 83.91812896728516%\n",
      "precision of the model on thevalidationdata: 47.69530487060547%\n",
      "Epoch [78/800],step[31000] Loss:0.3711\n",
      "precision of the model on thetrainingdata: 83.59788513183594%\n",
      "precision of the model on thevalidationdata: 48.17292404174805%\n",
      "Epoch [80/800],step[32000] Loss:0.4121\n",
      "precision of the model on thetrainingdata: 85.31073760986328%\n",
      "precision of the model on thevalidationdata: 47.80510330200195%\n",
      "Epoch [83/800],step[33000] Loss:0.3669\n",
      "precision of the model on thetrainingdata: 83.72093200683594%\n",
      "precision of the model on thevalidationdata: 48.09126663208008%\n",
      "Epoch [85/800],step[34000] Loss:0.4060\n",
      "precision of the model on thetrainingdata: 85.40372467041016%\n",
      "precision of the model on thevalidationdata: 47.88455581665039%\n",
      "Epoch [88/800],step[35000] Loss:0.3557\n",
      "precision of the model on thetrainingdata: 83.58209228515625%\n",
      "precision of the model on thevalidationdata: 48.20610427856445%\n",
      "Epoch [90/800],step[36000] Loss:0.3741\n",
      "precision of the model on thetrainingdata: 87.73841857910156%\n",
      "precision of the model on thevalidationdata: 48.08340835571289%\n",
      "Epoch [93/800],step[37000] Loss:0.3599\n",
      "precision of the model on thetrainingdata: 84.28927612304688%\n",
      "precision of the model on thevalidationdata: 47.95478057861328%\n",
      "Epoch [96/800],step[38000] Loss:0.4207\n",
      "precision of the model on thetrainingdata: 87.83382415771484%\n",
      "precision of the model on thevalidationdata: 47.74945068359375%\n",
      "Epoch [98/800],step[39000] Loss:0.3611\n",
      "precision of the model on thetrainingdata: 81.57247924804688%\n",
      "precision of the model on thevalidationdata: 47.995121002197266%\n",
      "Epoch [101/800],step[40000] Loss:0.3520\n",
      "precision of the model on thetrainingdata: 89.7727279663086%\n",
      "precision of the model on thevalidationdata: 47.379417419433594%\n",
      "Epoch [103/800],step[41000] Loss:0.3593\n",
      "precision of the model on thetrainingdata: 83.910888671875%\n",
      "precision of the model on thevalidationdata: 47.78434371948242%\n",
      "Epoch [106/800],step[42000] Loss:0.3222\n",
      "precision of the model on thetrainingdata: 90.90908813476562%\n",
      "precision of the model on thevalidationdata: 48.126220703125%\n",
      "Epoch [108/800],step[43000] Loss:0.3459\n",
      "precision of the model on thetrainingdata: 89.1598892211914%\n",
      "precision of the model on thevalidationdata: 47.901119232177734%\n",
      "Epoch [111/800],step[44000] Loss:0.3357\n",
      "precision of the model on thetrainingdata: 88.1401596069336%\n",
      "precision of the model on thevalidationdata: 47.47364807128906%\n",
      "Epoch [114/800],step[45000] Loss:0.3120\n",
      "precision of the model on thetrainingdata: 88.86138916015625%\n",
      "precision of the model on thevalidationdata: 47.915157318115234%\n",
      "Epoch [116/800],step[46000] Loss:0.3199\n",
      "precision of the model on thetrainingdata: 92.0%\n",
      "precision of the model on thevalidationdata: 48.072696685791016%\n",
      "Epoch [119/800],step[47000] Loss:0.3017\n",
      "precision of the model on thetrainingdata: 89.27680969238281%\n",
      "precision of the model on thevalidationdata: 48.24237060546875%\n",
      "Epoch [121/800],step[48000] Loss:0.3445\n",
      "precision of the model on thetrainingdata: 85.74821472167969%\n",
      "precision of the model on thevalidationdata: 48.206077575683594%\n",
      "Epoch [124/800],step[49000] Loss:0.3227\n",
      "precision of the model on thetrainingdata: 87.5634536743164%\n",
      "precision of the model on thevalidationdata: 48.15211486816406%\n",
      "Epoch [126/800],step[50000] Loss:0.3179\n",
      "precision of the model on thetrainingdata: 87.79840850830078%\n",
      "precision of the model on thevalidationdata: 48.023681640625%\n",
      "Epoch [129/800],step[51000] Loss:0.2948\n",
      "precision of the model on thetrainingdata: 88.295166015625%\n",
      "precision of the model on thevalidationdata: 48.08526611328125%\n",
      "Epoch [132/800],step[52000] Loss:0.2898\n",
      "precision of the model on thetrainingdata: 92.36842346191406%\n",
      "precision of the model on thevalidationdata: 47.71473693847656%\n",
      "Epoch [134/800],step[53000] Loss:0.2893\n",
      "precision of the model on thetrainingdata: 91.3838119506836%\n",
      "precision of the model on thevalidationdata: 47.930171966552734%\n",
      "Epoch [137/800],step[54000] Loss:0.2968\n",
      "precision of the model on thetrainingdata: 88.49105072021484%\n",
      "precision of the model on thevalidationdata: 48.349082946777344%\n",
      "Epoch [139/800],step[55000] Loss:0.3114\n",
      "precision of the model on thetrainingdata: 92.32804107666016%\n",
      "precision of the model on thevalidationdata: 47.945674896240234%\n",
      "Epoch [142/800],step[56000] Loss:0.3302\n",
      "precision of the model on thetrainingdata: 82.3798599243164%\n",
      "precision of the model on thevalidationdata: 48.416290283203125%\n",
      "Epoch [144/800],step[57000] Loss:0.2899\n",
      "precision of the model on thetrainingdata: 90.6474838256836%\n",
      "precision of the model on thevalidationdata: 48.149147033691406%\n",
      "Epoch [147/800],step[58000] Loss:0.2997\n",
      "precision of the model on thetrainingdata: 90.64327239990234%\n",
      "precision of the model on thevalidationdata: 48.11043167114258%\n",
      "Epoch [150/800],step[59000] Loss:0.2880\n",
      "precision of the model on thetrainingdata: 83.66336822509766%\n",
      "precision of the model on thevalidationdata: 47.63487243652344%\n",
      "Epoch [152/800],step[60000] Loss:0.2974\n",
      "precision of the model on thetrainingdata: 92.83489227294922%\n",
      "precision of the model on thevalidationdata: 47.24011993408203%\n",
      "Epoch [155/800],step[61000] Loss:0.2926\n",
      "precision of the model on thetrainingdata: 88.3211669921875%\n",
      "precision of the model on thevalidationdata: 47.90069580078125%\n",
      "Epoch [157/800],step[62000] Loss:0.2904\n",
      "precision of the model on thetrainingdata: 90.625%\n",
      "precision of the model on thevalidationdata: 47.69599533081055%\n",
      "Epoch [160/800],step[63000] Loss:0.2792\n",
      "precision of the model on thetrainingdata: 92.68292999267578%\n",
      "precision of the model on thevalidationdata: 47.568275451660156%\n",
      "Epoch [162/800],step[64000] Loss:0.2748\n",
      "precision of the model on thetrainingdata: 89.13580322265625%\n",
      "precision of the model on thevalidationdata: 47.87546920776367%\n",
      "Epoch [165/800],step[65000] Loss:0.2764\n",
      "precision of the model on thetrainingdata: 88.63108825683594%\n",
      "precision of the model on thevalidationdata: 47.79451370239258%\n",
      "Epoch [168/800],step[66000] Loss:0.2879\n",
      "precision of the model on thetrainingdata: 90.74549865722656%\n",
      "precision of the model on thevalidationdata: 47.830474853515625%\n",
      "Epoch [170/800],step[67000] Loss:0.2680\n",
      "precision of the model on thetrainingdata: 89.80099487304688%\n",
      "precision of the model on thevalidationdata: 47.82006072998047%\n",
      "Epoch [173/800],step[68000] Loss:0.2831\n",
      "precision of the model on thetrainingdata: 95.91280364990234%\n",
      "precision of the model on thevalidationdata: 48.06861877441406%\n",
      "Epoch [175/800],step[69000] Loss:0.2842\n",
      "precision of the model on thetrainingdata: 91.29353332519531%\n",
      "precision of the model on thevalidationdata: 47.772220611572266%\n",
      "Epoch [178/800],step[70000] Loss:0.2852\n",
      "precision of the model on thetrainingdata: 89.05109405517578%\n",
      "precision of the model on thevalidationdata: 47.90631103515625%\n",
      "Epoch [180/800],step[71000] Loss:0.2725\n",
      "precision of the model on thetrainingdata: 94.13265228271484%\n",
      "precision of the model on thevalidationdata: 47.51716613769531%\n",
      "Epoch [183/800],step[72000] Loss:0.2759\n",
      "precision of the model on thetrainingdata: 89.1891860961914%\n",
      "precision of the model on thevalidationdata: 47.653934478759766%\n",
      "Epoch [186/800],step[73000] Loss:0.2477\n",
      "precision of the model on thetrainingdata: 92.17171478271484%\n",
      "precision of the model on thevalidationdata: 47.78718566894531%\n",
      "Epoch [188/800],step[74000] Loss:0.2778\n",
      "precision of the model on thetrainingdata: 93.07691955566406%\n",
      "precision of the model on thevalidationdata: 47.72520065307617%\n",
      "Epoch [191/800],step[75000] Loss:0.2540\n",
      "precision of the model on thetrainingdata: 93.96551513671875%\n",
      "precision of the model on thevalidationdata: 47.86948776245117%\n",
      "Epoch [193/800],step[76000] Loss:0.2553\n",
      "precision of the model on thetrainingdata: 92.36640930175781%\n",
      "precision of the model on thevalidationdata: 47.51229476928711%\n",
      "Epoch [196/800],step[77000] Loss:0.2954\n",
      "precision of the model on thetrainingdata: 93.9632568359375%\n",
      "precision of the model on thevalidationdata: 47.53843688964844%\n",
      "Epoch [198/800],step[78000] Loss:0.2633\n",
      "precision of the model on thetrainingdata: 91.089111328125%\n",
      "precision of the model on thevalidationdata: 47.800537109375%\n",
      "Epoch [201/800],step[79000] Loss:0.2528\n",
      "precision of the model on thetrainingdata: 91.0669937133789%\n",
      "precision of the model on thevalidationdata: 48.179473876953125%\n",
      "Epoch [204/800],step[80000] Loss:0.2385\n",
      "precision of the model on thetrainingdata: 92.2680435180664%\n",
      "precision of the model on thevalidationdata: 47.795989990234375%\n",
      "Epoch [206/800],step[81000] Loss:0.2521\n",
      "precision of the model on thetrainingdata: 92.85713958740234%\n",
      "precision of the model on thevalidationdata: 47.95226287841797%\n",
      "Epoch [209/800],step[82000] Loss:0.2333\n",
      "precision of the model on thetrainingdata: 83.89513397216797%\n",
      "precision of the model on thevalidationdata: 47.964698791503906%\n",
      "Epoch [211/800],step[83000] Loss:0.2607\n",
      "precision of the model on thetrainingdata: 92.14659881591797%\n",
      "precision of the model on thevalidationdata: 48.04023361206055%\n",
      "Epoch [214/800],step[84000] Loss:0.2339\n",
      "precision of the model on thetrainingdata: 93.71858978271484%\n",
      "precision of the model on thevalidationdata: 47.90040588378906%\n",
      "Epoch [216/800],step[85000] Loss:0.2408\n",
      "precision of the model on thetrainingdata: 93.80952453613281%\n",
      "precision of the model on thevalidationdata: 48.00593185424805%\n",
      "Epoch [219/800],step[86000] Loss:0.2461\n",
      "precision of the model on thetrainingdata: 92.00968170166016%\n",
      "precision of the model on thevalidationdata: 48.105350494384766%\n",
      "Epoch [222/800],step[87000] Loss:0.2644\n",
      "precision of the model on thetrainingdata: 93.14720916748047%\n",
      "precision of the model on thevalidationdata: 47.89216613769531%\n",
      "Epoch [224/800],step[88000] Loss:0.2496\n",
      "precision of the model on thetrainingdata: 86.28691864013672%\n",
      "precision of the model on thevalidationdata: 47.97344970703125%\n",
      "Epoch [227/800],step[89000] Loss:0.2264\n",
      "precision of the model on thetrainingdata: 88.7828140258789%\n",
      "precision of the model on thevalidationdata: 48.09463882446289%\n",
      "Epoch [229/800],step[90000] Loss:0.2378\n",
      "precision of the model on thetrainingdata: 92.11956787109375%\n",
      "precision of the model on thevalidationdata: 47.44337844848633%\n",
      "Epoch [232/800],step[91000] Loss:0.2383\n",
      "precision of the model on thetrainingdata: 91.95121765136719%\n",
      "precision of the model on thevalidationdata: 47.96139144897461%\n",
      "Epoch [234/800],step[92000] Loss:0.2330\n",
      "precision of the model on thetrainingdata: 94.50261688232422%\n",
      "precision of the model on thevalidationdata: 48.03429412841797%\n",
      "Epoch [237/800],step[93000] Loss:0.2455\n",
      "precision of the model on thetrainingdata: 93.05912780761719%\n",
      "precision of the model on thevalidationdata: 47.85073471069336%\n",
      "Epoch [240/800],step[94000] Loss:0.2599\n",
      "precision of the model on thetrainingdata: 89.97493743896484%\n",
      "precision of the model on thevalidationdata: 47.95481491088867%\n",
      "Epoch [242/800],step[95000] Loss:0.2465\n",
      "precision of the model on thetrainingdata: 93.5732650756836%\n",
      "precision of the model on thevalidationdata: 47.719810485839844%\n",
      "Epoch [245/800],step[96000] Loss:0.2636\n",
      "precision of the model on thetrainingdata: 94.91978454589844%\n",
      "precision of the model on thevalidationdata: 47.510154724121094%\n",
      "Epoch [247/800],step[97000] Loss:0.2197\n",
      "precision of the model on thetrainingdata: 94.30052185058594%\n",
      "precision of the model on thevalidationdata: 47.49169158935547%\n",
      "Epoch [250/800],step[98000] Loss:0.2406\n",
      "precision of the model on thetrainingdata: 94.14520263671875%\n",
      "precision of the model on thevalidationdata: 47.38772201538086%\n",
      "Epoch [252/800],step[99000] Loss:0.2216\n",
      "precision of the model on thetrainingdata: 96.41148376464844%\n",
      "precision of the model on thevalidationdata: 48.11174774169922%\n",
      "Epoch [255/800],step[100000] Loss:0.2580\n",
      "precision of the model on thetrainingdata: 88.81118774414062%\n",
      "precision of the model on thevalidationdata: 48.09877395629883%\n",
      "Epoch [258/800],step[101000] Loss:0.2455\n",
      "precision of the model on thetrainingdata: 90.53398132324219%\n",
      "precision of the model on thevalidationdata: 48.03941345214844%\n",
      "Epoch [260/800],step[102000] Loss:0.2763\n",
      "precision of the model on thetrainingdata: 90.90908813476562%\n",
      "precision of the model on thevalidationdata: 47.77070236206055%\n",
      "Epoch [263/800],step[103000] Loss:0.2342\n",
      "precision of the model on thetrainingdata: 94.0758285522461%\n",
      "precision of the model on thevalidationdata: 47.978424072265625%\n",
      "Epoch [265/800],step[104000] Loss:0.2340\n",
      "precision of the model on thetrainingdata: 94.80519104003906%\n",
      "precision of the model on thevalidationdata: 47.64140701293945%\n",
      "Epoch [268/800],step[105000] Loss:0.2145\n",
      "precision of the model on thetrainingdata: 93.59606170654297%\n",
      "precision of the model on thevalidationdata: 47.72541046142578%\n",
      "Epoch [270/800],step[106000] Loss:0.2375\n",
      "precision of the model on thetrainingdata: 92.83887481689453%\n",
      "precision of the model on thevalidationdata: 47.51593780517578%\n",
      "Epoch [273/800],step[107000] Loss:0.2529\n",
      "precision of the model on thetrainingdata: 85.07794952392578%\n",
      "precision of the model on thevalidationdata: 48.3085823059082%\n",
      "Epoch [276/800],step[108000] Loss:0.2461\n",
      "precision of the model on thetrainingdata: 88.60465240478516%\n",
      "precision of the model on thevalidationdata: 48.11479568481445%\n",
      "Epoch [278/800],step[109000] Loss:0.2122\n",
      "precision of the model on thetrainingdata: 93.6117935180664%\n",
      "precision of the model on thevalidationdata: 47.73041534423828%\n",
      "Epoch [281/800],step[110000] Loss:0.1854\n",
      "precision of the model on thetrainingdata: 93.2126693725586%\n",
      "precision of the model on thevalidationdata: 47.84565353393555%\n",
      "Epoch [283/800],step[111000] Loss:0.2394\n",
      "precision of the model on thetrainingdata: 90.81632995605469%\n",
      "precision of the model on thevalidationdata: 47.76696014404297%\n",
      "Epoch [286/800],step[112000] Loss:0.2018\n",
      "precision of the model on thetrainingdata: 92.71844482421875%\n",
      "precision of the model on thevalidationdata: 47.942989349365234%\n",
      "Epoch [288/800],step[113000] Loss:0.2293\n",
      "precision of the model on thetrainingdata: 92.3990478515625%\n",
      "precision of the model on thevalidationdata: 47.7785758972168%\n",
      "Epoch [291/800],step[114000] Loss:0.2246\n",
      "precision of the model on thetrainingdata: 93.14421081542969%\n",
      "precision of the model on thevalidationdata: 47.49697494506836%\n",
      "Epoch [294/800],step[115000] Loss:0.2271\n",
      "precision of the model on thetrainingdata: 93.64302825927734%\n",
      "precision of the model on thevalidationdata: 47.982452392578125%\n",
      "Epoch [296/800],step[116000] Loss:0.2232\n",
      "precision of the model on thetrainingdata: 96.3254623413086%\n",
      "precision of the model on thevalidationdata: 47.552215576171875%\n",
      "Epoch [299/800],step[117000] Loss:0.2132\n",
      "precision of the model on thetrainingdata: 93.96134948730469%\n",
      "precision of the model on thevalidationdata: 47.7474250793457%\n",
      "Epoch [301/800],step[118000] Loss:0.2180\n",
      "precision of the model on thetrainingdata: 94.00479888916016%\n",
      "precision of the model on thevalidationdata: 48.01345443725586%\n",
      "Epoch [304/800],step[119000] Loss:0.2014\n",
      "precision of the model on thetrainingdata: 91.17646789550781%\n",
      "precision of the model on thevalidationdata: 48.00748062133789%\n",
      "Epoch [306/800],step[120000] Loss:0.2261\n",
      "precision of the model on thetrainingdata: 93.85749053955078%\n",
      "precision of the model on thevalidationdata: 47.94506072998047%\n",
      "Epoch [309/800],step[121000] Loss:0.2074\n",
      "precision of the model on thetrainingdata: 89.6713638305664%\n",
      "precision of the model on thevalidationdata: 47.686885833740234%\n",
      "Epoch [312/800],step[122000] Loss:0.2450\n",
      "precision of the model on thetrainingdata: 86.84210205078125%\n",
      "precision of the model on thevalidationdata: 48.52653121948242%\n",
      "Epoch [314/800],step[123000] Loss:0.2117\n",
      "precision of the model on thetrainingdata: 93.4065933227539%\n",
      "precision of the model on thevalidationdata: 48.04762268066406%\n",
      "Epoch [317/800],step[124000] Loss:0.2350\n",
      "precision of the model on thetrainingdata: 93.5064926147461%\n",
      "precision of the model on thevalidationdata: 47.88140106201172%\n",
      "Epoch [319/800],step[125000] Loss:0.2344\n",
      "precision of the model on thetrainingdata: 94.29280090332031%\n",
      "precision of the model on thevalidationdata: 47.81233596801758%\n",
      "Epoch [322/800],step[126000] Loss:0.2009\n",
      "precision of the model on thetrainingdata: 93.48837280273438%\n",
      "precision of the model on thevalidationdata: 48.07217025756836%\n",
      "Epoch [324/800],step[127000] Loss:0.2026\n",
      "precision of the model on thetrainingdata: 96.82926940917969%\n",
      "precision of the model on thevalidationdata: 47.59313201904297%\n",
      "Epoch [327/800],step[128000] Loss:0.2108\n",
      "precision of the model on thetrainingdata: 92.4485092163086%\n",
      "precision of the model on thevalidationdata: 48.02069854736328%\n",
      "Epoch [330/800],step[129000] Loss:0.2354\n",
      "precision of the model on thetrainingdata: 91.16944885253906%\n",
      "precision of the model on thevalidationdata: 47.67441940307617%\n",
      "Epoch [332/800],step[130000] Loss:0.2244\n",
      "precision of the model on thetrainingdata: 86.0465087890625%\n",
      "precision of the model on thevalidationdata: 48.16987228393555%\n",
      "Epoch [335/800],step[131000] Loss:0.2203\n",
      "precision of the model on thetrainingdata: 93.38235473632812%\n",
      "precision of the model on thevalidationdata: 47.5762825012207%\n",
      "Epoch [337/800],step[132000] Loss:0.2229\n",
      "precision of the model on thetrainingdata: 95.04950714111328%\n",
      "precision of the model on thevalidationdata: 47.43815231323242%\n",
      "Epoch [340/800],step[133000] Loss:0.2185\n",
      "precision of the model on thetrainingdata: 92.96116638183594%\n",
      "precision of the model on thevalidationdata: 48.111968994140625%\n",
      "Epoch [342/800],step[134000] Loss:0.2231\n",
      "precision of the model on thetrainingdata: 92.61904907226562%\n",
      "precision of the model on thevalidationdata: 47.720252990722656%\n",
      "Epoch [345/800],step[135000] Loss:0.2104\n",
      "precision of the model on thetrainingdata: 95.95237731933594%\n",
      "precision of the model on thevalidationdata: 47.84078598022461%\n",
      "Epoch [348/800],step[136000] Loss:0.2952\n",
      "precision of the model on thetrainingdata: 90.88784790039062%\n",
      "precision of the model on thevalidationdata: 47.484962463378906%\n",
      "Epoch [350/800],step[137000] Loss:0.2054\n",
      "precision of the model on thetrainingdata: 91.03138732910156%\n",
      "precision of the model on thevalidationdata: 48.161964416503906%\n",
      "Epoch [353/800],step[138000] Loss:0.1847\n",
      "precision of the model on thetrainingdata: 93.5779800415039%\n",
      "precision of the model on thevalidationdata: 48.296695709228516%\n",
      "Epoch [355/800],step[139000] Loss:0.2269\n",
      "precision of the model on thetrainingdata: 90.19607543945312%\n",
      "precision of the model on thevalidationdata: 48.02059555053711%\n",
      "Epoch [358/800],step[140000] Loss:0.1847\n",
      "precision of the model on thetrainingdata: 93.00225830078125%\n",
      "precision of the model on thevalidationdata: 47.76954650878906%\n",
      "Epoch [360/800],step[141000] Loss:0.2241\n",
      "precision of the model on thetrainingdata: 93.66197204589844%\n",
      "precision of the model on thevalidationdata: 47.75892639160156%\n",
      "Epoch [363/800],step[142000] Loss:0.2210\n",
      "precision of the model on thetrainingdata: 93.28536987304688%\n",
      "precision of the model on thevalidationdata: 47.72870635986328%\n",
      "Epoch [366/800],step[143000] Loss:0.2157\n",
      "precision of the model on thetrainingdata: 93.33333587646484%\n",
      "precision of the model on thevalidationdata: 47.619049072265625%\n",
      "Epoch [368/800],step[144000] Loss:0.2074\n",
      "precision of the model on thetrainingdata: 91.77489471435547%\n",
      "precision of the model on thevalidationdata: 47.9406852722168%\n",
      "Epoch [371/800],step[145000] Loss:0.2292\n",
      "precision of the model on thetrainingdata: 94.30693054199219%\n",
      "precision of the model on thevalidationdata: 47.89979934692383%\n",
      "Epoch [373/800],step[146000] Loss:0.2023\n",
      "precision of the model on thetrainingdata: 96.99453735351562%\n",
      "precision of the model on thevalidationdata: 47.624481201171875%\n",
      "Epoch [376/800],step[147000] Loss:0.2017\n",
      "precision of the model on thetrainingdata: 82.38636016845703%\n",
      "precision of the model on thevalidationdata: 48.26521301269531%\n",
      "Epoch [378/800],step[148000] Loss:0.2062\n",
      "precision of the model on thetrainingdata: 93.45794677734375%\n",
      "precision of the model on thevalidationdata: 47.665565490722656%\n",
      "Epoch [381/800],step[149000] Loss:0.2081\n",
      "precision of the model on thetrainingdata: 94.04762268066406%\n",
      "precision of the model on thevalidationdata: 47.568084716796875%\n",
      "Epoch [384/800],step[150000] Loss:0.2172\n",
      "precision of the model on thetrainingdata: 91.91011047363281%\n",
      "precision of the model on thevalidationdata: 47.831485748291016%\n",
      "Epoch [386/800],step[151000] Loss:0.1965\n",
      "precision of the model on thetrainingdata: 91.51376342773438%\n",
      "precision of the model on thevalidationdata: 48.21598815917969%\n",
      "Epoch [389/800],step[152000] Loss:0.1979\n",
      "precision of the model on thetrainingdata: 94.30693054199219%\n",
      "precision of the model on thevalidationdata: 47.96421432495117%\n",
      "Epoch [391/800],step[153000] Loss:0.2110\n",
      "precision of the model on thetrainingdata: 94.40389251708984%\n",
      "precision of the model on thevalidationdata: 48.22118377685547%\n",
      "Epoch [394/800],step[154000] Loss:0.2059\n",
      "precision of the model on thetrainingdata: 95.23809814453125%\n",
      "precision of the model on thevalidationdata: 47.63043212890625%\n",
      "Epoch [396/800],step[155000] Loss:0.1756\n",
      "precision of the model on thetrainingdata: 93.30254364013672%\n",
      "precision of the model on thevalidationdata: 48.18829345703125%\n",
      "Epoch [399/800],step[156000] Loss:0.1900\n",
      "precision of the model on thetrainingdata: 93.89671325683594%\n",
      "precision of the model on thevalidationdata: 47.85837936401367%\n",
      "Epoch [402/800],step[157000] Loss:0.2343\n",
      "precision of the model on thetrainingdata: 94.32989501953125%\n",
      "precision of the model on thevalidationdata: 47.91792297363281%\n",
      "Epoch [404/800],step[158000] Loss:0.1868\n",
      "precision of the model on thetrainingdata: 93.34862518310547%\n",
      "precision of the model on thevalidationdata: 47.9887809753418%\n",
      "Epoch [407/800],step[159000] Loss:0.2268\n",
      "precision of the model on thetrainingdata: 92.0091323852539%\n",
      "precision of the model on thevalidationdata: 47.88515853881836%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-864c3f90e3e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mtotal_step\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#each 10 iterations is one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mamsgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amsgrad'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;31m# State initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#训练过程\n",
    "for epoch in range(500):\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images=images.type(torch.FloatTensor)\n",
    "        labels=labels.type(torch.FloatTensor)\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        #forward pass\n",
    "        outputs=lstm(images)\n",
    "        loss=loss_function(outputs,labels.long())\n",
    "        \n",
    "        #Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_step+=1\n",
    "        if (total_step)%1000==0:#each 10 iterations is one epoch\n",
    "            print(\"Epoch [{}/{}],step[{}] Loss:{:.4f}\".format(epoch+1,num_epochs,total_step,loss.item()))\n",
    "            _,train_pre=predict_precision(lstm,images,labels,device,predict_type='training')\n",
    "            train_precision.append(train_pre)\n",
    "            for images, labels in valid_loader:\n",
    "                _,valid_pre=predict_precision(lstm,images,labels,device,predict_type='validation')\n",
    "            valid_precision.append(valid_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_precision,label=\"training precision\")\n",
    "plt.plot(valid_precision,label=\"validation precision\")\n",
    "plt.title(\"LSTM on stock\")\n",
    "plt.xlabel(\"1000*x training step\")\n",
    "plt.ylabel(\"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size2 = 4096\n",
    "lstm2 = LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes,device=device)\n",
    "lstm2.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(lstm2.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=GetLoader(train_data,train_label)\n",
    "valid=GetLoader(valid_data,valid_label)\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train,batch_size=batch_size2,shuffle=True,num_workers=0)\n",
    "valid_loader=torch.utils.data.DataLoader(dataset=valid,batch_size=valid_data.shape[0],shuffle=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step=0\n",
    "train_precision2=[]\n",
    "valid_precision2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(lstm2.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#训练过程\n",
    "for epoch in range(2000):\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images=images.type(torch.FloatTensor)\n",
    "        labels=labels.type(torch.FloatTensor)\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        #forward pass\n",
    "        outputs=lstm2(images)\n",
    "        loss=loss_function(outputs,labels.long())\n",
    "        \n",
    "        #Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_step+=1\n",
    "        if (total_step)%1000==0:#each 10 iterations is one epoch\n",
    "            print(\"Epoch [{}/{}],step[{}] Loss:{:.4f}\".format(epoch+1,num_epochs,total_step,loss.item()))\n",
    "            _,train_pre=predict_precision(lstm2,images,labels,device,predict_type='training')\n",
    "            train_precision2.append(train_pre)\n",
    "            for images, labels in valid_loader:\n",
    "                _,valid_pre=predict_precision(lstm2,images,labels,device,predict_type='validation')\n",
    "            valid_precision2.append(valid_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_precision2,label=\"training precision\")\n",
    "plt.plot(valid_precision2,label=\"validation precision\")\n",
    "plt.title(\"LSTM on stock(with bigger batch_size)\")\n",
    "plt.xlabel(\"1000*x training step\")\n",
    "plt.ylabel(\"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "sequence_length = 10  # 序列长度，将图像的每一列作为一个序列\n",
    "in_channel = 42\n",
    "out_channel=32\n",
    "hidden_size = 64  # 隐藏层的size\n",
    "num_layers =  1 # 有多少层\n",
    "\n",
    "num_classes = 2\n",
    "batch_size = 512\n",
    "num_epochs = 10000\n",
    "learning_rate = 0.001\n",
    "\n",
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONV1D_LSTM(nn.Module):\n",
    "    def __init__(self ,in_channel,out_channel, hidden_size, num_layers, num_classes,device=torch.device(\"cuda:1\")):\n",
    "        super(CONV1D_LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channel, out_channels=out_channel,kernel_size=1, stride=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channel)\n",
    "        self.conv2 = nn.Conv1d(in_channels=out_channel, out_channels=out_channel,kernel_size=1, stride=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstm = nn.LSTM(out_channel, hidden_size, num_layers, batch_first=True)  # batch_first=True仅仅针对输入而言\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight.to(device), mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #forward prop\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out=torch.transpose(out,2,1)\n",
    "        #因为pytorch里lstm和conv1d的input sequence位置不一样，需要调整。\n",
    "        \n",
    "        # 设置初始状态h_0与c_0的状态是初始的状态，一般设置为0，尺寸是,x.size(0)\n",
    "        h0 = Variable(torch.zeros(self.num_layers, out.size(0), self.hidden_size)).to(device)\n",
    "        c0 = Variable(torch.zeros(self.num_layers, out.size(0), self.hidden_size)).to(device)\n",
    "\n",
    "        # Forward propagate RNN\n",
    "        out, (h_n, c_n) = self.lstm(out, (h0, c0))  # 送入一个初始的x值，作为输入以及(h0, c0)\n",
    "        # Decode hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])  # output也是batch_first, 实际上h_n与c_n并不是batch_first\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from classification_models import CONV1D_LSTM\n",
    "conv1d_lstm = CONV1D_LSTM(in_channel=in_channel, out_channel=out_channel,\n",
    "                   hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes,device=device)\n",
    "conv1d_lstm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=np.transpose(train_data,(0,2,1))\n",
    "valid_data=np.transpose(valid_data,(0,2,1))\n",
    "train=GetLoader(train_data,train_label)\n",
    "valid=GetLoader(valid_data,valid_label)\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train,batch_size=batch_size,shuffle=True,num_workers=0)\n",
    "valid_loader=torch.utils.data.DataLoader(dataset=valid,batch_size=valid_data.shape[0],shuffle=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step=0\n",
    "train_precision=[]\n",
    "valid_precision=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(conv1d_lstm.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#训练过程\n",
    "#出现的问题：把learning rate设为0.1和0.01，都会出现diverge问题\n",
    "#把learning_rate设为0.0001时在2000epoch左右（其他超参同上方超参表）时会出现loss无法进一步缩小的问题\n",
    "total_step=0\n",
    "for epoch in range(num_epochs):\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images=images.type(torch.FloatTensor)\n",
    "        labels=labels.type(torch.FloatTensor)\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        #forward pass\n",
    "        outputs=conv1d_lstm(images)\n",
    "        loss=loss_function(outputs,labels.long())\n",
    "        \n",
    "        #Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_step+=1\n",
    "        if (total_step)%1000==0:\n",
    "            print(\"Epoch [{}/{}],step[{}] Loss:{:.4f}\".format(epoch+1,num_epochs,total_step,loss.item()))\n",
    "            _,train_pre=predict_precision(conv1d_lstm,images,labels,device,predict_type='training')\n",
    "            train_precision.append(train_pre)\n",
    "            for images, labels in valid_loader:\n",
    "                _,valid_pre=predict_precision(conv1d_lstm,images,labels,device,predict_type='validation')\n",
    "            valid_precision.append(valid_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_precision,label=\"training precision\")\n",
    "plt.plot(valid_precision,label=\"validation precision\")\n",
    "plt.title(\"conv1d_lstm on stock\")\n",
    "plt.xlabel(\"1000*x training step\")\n",
    "plt.ylabel(\"precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练过程总结：\n",
    "使用以下超参时：\n",
    "\n",
    "$Hyper Parameters\n",
    "sequence_length = 10  # 序列长度，将图像的每一列作为一个序列\n",
    "in_channel = 42\n",
    "out_channel=32\n",
    "hidden_size = 64  # 隐藏层的size\n",
    "num_layers =  2 # 有多少层\n",
    "num_classes = 2\n",
    "batch_size = 1024\n",
    "num_epochs = 10000\n",
    "learning_rate = 0.0001\n",
    "device = torch.device(\"cuda:1\")$\n",
    "\n",
    "\n",
    "出现的问题：把learning rate设为0.1和0.01，都会出现diverge问题\n",
    "把learning_rate设为0.0001时在2000epoch左右（其他超参同上方超参表）激活函数为leakyrelu,lstm两层时会出现loss无法进一步缩小的问题(pic3),初步认为是因为梯度消失导致的问题，对此想出的解决办法为：\n",
    "\n",
    "\n",
    "（1）调整激活参数为relu。若有效，可进一步考虑使用更深层次的网络结构\n",
    "\n",
    "\n",
    "$Hyper Parameters\n",
    "sequence_length = 10  # 序列长度，将图像的每一列作为一个序列\n",
    "in_channel = 42\n",
    "out_channel=32\n",
    "hidden_size = 64  # 隐藏层的size\n",
    "num_layers =  1 # 有多少层\n",
    "num_classes = 2\n",
    "batch_size = 512\n",
    "num_epochs = 10000\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda:1\")$\n",
    "结果无效，比leakyrelu变差了。见pic4\n",
    "\n",
    "（2）使用不同的optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）调整激活参数为relu。若有效，可进一步考虑使用更深层次的网络结构\n",
    "$Hyper Parameters\n",
    "sequence_length = 10  # 序列长度，将图像的每一列作为一个序列\n",
    "in_channel = 42\n",
    "out_channel=32\n",
    "hidden_size = 64  # 隐藏层的size\n",
    "num_layers =  1 # 有多少层\n",
    "num_classes = 2\n",
    "batch_size = 512\n",
    "num_epochs = 10000\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda:1\")$\n",
    "结果无效，比leakyrelu变差了。见pic4\n",
    "\n",
    "（2）使用不同的optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
